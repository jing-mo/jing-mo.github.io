<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>基于深度学习的图像着色系统项目介绍 | Exiaの格纳库</title><meta name="keywords" content="人工智能"><meta name="author" content="Exia"><meta name="copyright" content="Exia"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="基于深度学习的图像着色系统项目介绍库的支持这里我们用到了以下的库  直接用pip命令安装txt文件中的上述库，非常方便 1pip install requirements.txt  torch1.1 torch.nn简介与功能nn是Neural Network的简称。 torch.nn模块是PyTorch提供的，帮助程序员方便（1）创建神经网络和（2）训练神经网络而提供的模块。主要功能包括：  创">
<meta property="og:type" content="article">
<meta property="og:title" content="基于深度学习的图像着色系统项目介绍">
<meta property="og:url" content="http://example.com/posts/1a3.html">
<meta property="og:site_name" content="Exiaの格纳库">
<meta property="og:description" content="基于深度学习的图像着色系统项目介绍库的支持这里我们用到了以下的库  直接用pip命令安装txt文件中的上述库，非常方便 1pip install requirements.txt  torch1.1 torch.nn简介与功能nn是Neural Network的简称。 torch.nn模块是PyTorch提供的，帮助程序员方便（1）创建神经网络和（2）训练神经网络而提供的模块。主要功能包括：  创">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ftp.bmp.ovh/imgs/2021/01/3d619086ccfbc6a9.jpg">
<meta property="article:published_time" content="2022-05-22T14:49:23.344Z">
<meta property="article:modified_time" content="2022-05-24T11:31:41.891Z">
<meta property="article:author" content="Exia">
<meta property="article:tag" content="人工智能">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ftp.bmp.ovh/imgs/2021/01/3d619086ccfbc6a9.jpg"><link rel="shortcut icon" href="/img/hello.ico"><link rel="canonical" href="http://example.com/posts/1a3"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"./public/search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-24 19:31:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}const fontSizeVal = saveToLocal.get('global-font-size')
if (fontSizeVal !== undefined) {
  document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
}})()</script><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/css/iconfont.css"><div class="aplayer" data-id="5155785432" data-server="netease" data-type="playlist" data-fixed="true" data-listFolded="false" data-order="random" data-preload="auto"></div><link rel="stylesheet" href="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.css"><script src="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script><link rel="stylesheet" href="APlayer.min.css"><div id="aplayer"></div><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js" async></script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home faa-bounce animated"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-leaf faa-bounce animated-hover"></i><span> 百宝箱</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.bilibili.com/"><i class="fa-fw fas fa-paw"></i><span> B站</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.csdn.net/"><i class="fa-fw fas fa-graduation-cap"></i><span> CSDN</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-book faa-bounce animated-hover"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive faa-bounce animated-hover"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags faa-bounce animated-hover"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open faa-bounce animated-hover"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list faa-spin animated"></i><span> 京墨杂谈</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music faa-bounce animated-hover"></i><span> 音乐</span></a></li><li><a class="site-page" href="/photo/"><i class="fa-fw fas fa-image faa-bounce animated-hover"></i><span> 相册</span></a></li><li><a class="site-page" href="/bangumis/"><i class="fa-fw fas fa-video faa-bounce animated-hover"></i><span> 追番</span></a></li><li><a class="site-page" href="/cinemas/"><i class="fa-fw fas fa-video faa-bounce animated-hover"></i><span> 看剧</span></a></li><li><a class="site-page" href="/artitalk/"><i class="fa-fw fas fa-comment faa-bounce animated-hover"></i><span> 说说</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link faa-flash animated"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/bbs/"><i class="fa-fw fas fa-window-maximize"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 豆瓣</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-film"></i><span> 电影</span></a></li><li><a class="site-page" href="/games/"><i class="fa-fw fas fa-gamepad"></i><span> 游戏</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-heart faa-bounce animated-hover"></i><span> 关于</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart faa-bounce animated-hover"></i><span> 我的</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://ftp.bmp.ovh/imgs/2021/01/3d619086ccfbc6a9.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Exiaの格纳库</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home faa-bounce animated"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-leaf faa-bounce animated-hover"></i><span> 百宝箱</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.bilibili.com/"><i class="fa-fw fas fa-paw"></i><span> B站</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.csdn.net/"><i class="fa-fw fas fa-graduation-cap"></i><span> CSDN</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-book faa-bounce animated-hover"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive faa-bounce animated-hover"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags faa-bounce animated-hover"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open faa-bounce animated-hover"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list faa-spin animated"></i><span> 京墨杂谈</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music faa-bounce animated-hover"></i><span> 音乐</span></a></li><li><a class="site-page" href="/photo/"><i class="fa-fw fas fa-image faa-bounce animated-hover"></i><span> 相册</span></a></li><li><a class="site-page" href="/bangumis/"><i class="fa-fw fas fa-video faa-bounce animated-hover"></i><span> 追番</span></a></li><li><a class="site-page" href="/cinemas/"><i class="fa-fw fas fa-video faa-bounce animated-hover"></i><span> 看剧</span></a></li><li><a class="site-page" href="/artitalk/"><i class="fa-fw fas fa-comment faa-bounce animated-hover"></i><span> 说说</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link faa-flash animated"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/bbs/"><i class="fa-fw fas fa-window-maximize"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 豆瓣</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-film"></i><span> 电影</span></a></li><li><a class="site-page" href="/games/"><i class="fa-fw fas fa-gamepad"></i><span> 游戏</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-heart faa-bounce animated-hover"></i><span> 关于</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart faa-bounce animated-hover"></i><span> 我的</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">基于深度学习的图像着色系统项目介绍</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-22T14:49:23.344Z" title="发表于 2022-05-22 22:49:23">2022-05-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-24T11:31:41.891Z" title="更新于 2022-05-24 19:31:41">2022-05-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="基于深度学习的图像着色系统项目介绍"><a href="#基于深度学习的图像着色系统项目介绍" class="headerlink" title="基于深度学习的图像着色系统项目介绍"></a><strong>基于深度学习的图像着色系统项目介绍</strong></h1><h2 id="库的支持"><a href="#库的支持" class="headerlink" title="库的支持"></a>库的支持</h2><p>这里我们用到了以下的库</p>
<p><img src="E:\MyBlog\public\img\库.png" alt="image-20220522164525844"></p>
<p>直接用pip命令安装txt文件中的上述库，非常方便</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requirements.txt</span><br></pre></td></tr></table></figure>

<h3 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h3><h4 id="1-1-torch-nn简介与功能"><a href="#1-1-torch-nn简介与功能" class="headerlink" title="1.1 torch.nn简介与功能"></a>1.1 torch.nn简介与功能</h4><p>nn是Neural Network的简称。</p>
<p>torch.nn模块是PyTorch提供的，帮助程序员方便（1）创建神经网络和（2）训练神经网络而提供的模块。主要功能包括：</p>
<ol>
<li>创建神经网络</li>
<li>训练神经网络</li>
</ol>
<h4 id="2-1-获取神经网络的模型参数"><a href="#2-1-获取神经网络的模型参数" class="headerlink" title="2.1 获取神经网络的模型参数"></a><strong>2.1 获取神经网络的模型参数</strong></h4><p>torch.nn.Parameter     获取模型参数</p>
<h5 id="项目中的重要方法总结与归纳"><a href="#项目中的重要方法总结与归纳" class="headerlink" title="项目中的重要方法总结与归纳:"></a>项目中的重要方法总结与归纳:</h5><p>将数据转换成Tensor，便于模型使用</p>
<p><strong>torch.nn.Module</strong>:</p>
<p>它是所有神经网络模块的基类。</p>
<p><strong>torch.nn.Conv2d</strong></p>
<p>  该软件包将用于在由多个输入平面组成的输入信号上应用2D卷积。</p>
<p><strong>BatchNorm2d()</strong></p>
<p>归一化</p>
<p>函数参数讲解：</p>
<p>BatchNorm2d()函数数学原理如下：</p>
<p>​                           <img src="https://img-blog.csdnimg.cn/20190612205637399.png" alt="img"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>1.num_features：一般输入参数为batch_sizenum_featuresheight*width，即为其中特征的数量，即为输入BN层的通道数；<br>2.eps：分母中添加的一个值，目的是为了计算的稳定性，默认为：1e-5,避免分母为0；<br>3.momentum：一个用于运行过程中均值和方差的一个估计参数（我的理解是一个稳定系数，类似于SGD中的momentum的系数）；<br>4.affine：当设为true时，会给定可以学习的系数矩阵gamma和beta</p>
<p><strong>torch.nn.ReLU</strong>  </p>
<p>它将按元素应用于整流线性单位函数：ReLU(x)= max(0, x)</p>
<p><strong>torch.nn.Upsample</strong>  </p>
<p>它用于对给定的多通道1D, 2D或3D数据进行升采样。</p>
<p><strong>张量tensor</strong></p>
<p><code>torch.Tensor()</code>是一个类，是默认张量类型torch.FloatTensor()的别名，用于生成一个单精度浮点类型的张量。</p>
<p><strong>张量连接</strong></p>
<ul>
<li><code>torch.cat(inputs, dimension=0) → Tensor</code>:在给定维度上对输入的张量序列seq 进行连接操作,只需满足指定纬度的长度相同</li>
</ul>
<p><strong>torch.nn.Sequential</strong></p>
<p>它是一个顺序容器,其中模块的添加顺序与在构造函数中传递模块时的顺序相同。</p>
<p><strong>torch.nn.Softmax</strong>  </p>
<p>它用于将softmax函数应用于n维输入张量以重新缩放它们。之后, n维输出Tensor的元素位于0、1的范围内, 且总和为1。</p>
<p><strong>torch.nn.ConvTranspose2d</strong>  </p>
<p>该软件包将用于在由多个输入平面组成的输入图像上应用2D转置卷积运算符。</p>
<p><strong>TORCH.NN.FUNCTIONAL.INTERPOLATE</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.interpolate(<span class="built_in">input</span>, size=<span class="literal">None</span>, scale_factor=<span class="literal">None</span>, mode=‘nearest’, align_corners=<span class="literal">None</span>, recompute_scale_factor=<span class="literal">None</span>, antialias=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>将输入input上采样或下采样到指定的size或缩放因子上scale_factor</p>
<p>resize使用的算法由mode参数决定,mode默认为nearest, 可选参数有nearest/linear(3D Inputs-only)/bilinear/bicubic(4D Inputs-only)/trilinear(5D Inputs-only)/area/nearest-exact</p>
<p>支持输入input为3/4/5维数据，输入数据维度的顺序为mini-batch x channels x [optional depth] x [optional height] x width</p>
<p>参数<br>input:输入向量<br>size(int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int])输出数据的空间尺度<br>mode (str) ：采样算法<br>align_corners：输出的结果是否角对齐，对插值后的边的处理方式有所不同，参考一文看懂align_corners<br>recompute_scale_factor:是否重新计算scale_factor,默认None，选择特定的插值方式时可用<br>align_corners为False和True时输出的对比：</p>
<p><img src="E:\MyBlog\public\img\TORCHNNFUNCTIONALINTERPOLATE.png" alt="image-20220522213718336"></p>
<h4 id="2-2-主要的容器"><a href="#2-2-主要的容器" class="headerlink" title="2.2 主要的容器"></a>2.2 主要的容器</h4><table>
<thead>
<tr>
<th>名称</th>
<th>Containers</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)<strong>torch.nn.Module</strong></td>
<td>它是所有神经网络模块的基类。</td>
<td></td>
</tr>
<tr>
<td>2)<strong>torch.nn.Sequential</strong></td>
<td><strong>它是一个顺序容器,其中模块的添加顺序与在构造函数中传递模块时的顺序相同。</strong></td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.ModuleList</td>
<td>这会将子模块保存在列表中。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.ModuleDict</td>
<td>这会将子模块保存在目录中。</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.ParameterList</td>
<td>这会将参数保存在列表中。</td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.parameterDict</td>
<td>这会将参数保存在目录中。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-3-线性层"><a href="#2-3-线性层" class="headerlink" title="2.3 线性层"></a>2.3 线性层</h4><table>
<thead>
<tr>
<th></th>
<th>线性层</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)PyTorch PlaceHolder</td>
<td>它是一个占位符身份运算符, 对参数不敏感。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.Linear</td>
<td>它用于对输入数据进行线性变换：y = xAT + b</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.Bilinear</td>
<td>它用于对输入数据进行双线性变换：y = x1 Ax2 + b</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-4-非线性激活函数"><a href="#2-4-非线性激活函数" class="headerlink" title="2.4 非线性激活函数"></a>2.4 非线性激活函数</h4><table>
<thead>
<tr>
<th></th>
<th>非线性激活(加权和, 非线性)</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.ELU</td>
<td>它将用于应用按元素的函数：ELU(x)= max(0, x)+ min(0, α*(exp(x)-1))</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.Hardshrink</td>
<td>它将用于应用硬收缩函数逐元素函数：</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.LeakyReLU</td>
<td>它将用于应用按元素的函数：LeakyReLu(x)= max(0, x)+ negative_slope * min(0, x)</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.LogSigmoid</td>
<td>它将用于应用逐元素函数：</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.MultiheadAttention</td>
<td>它用于允许模型关注来自不同表示子空间的信息</td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.PReLU</td>
<td>它将用于应用按元素的函数：PReLU(x)= max(0, x)+ a * min(0, x)</td>
<td></td>
</tr>
<tr>
<td>7)<strong>torch.nn.ReLU</strong></td>
<td><strong>它将按元素应用于整流线性单位函数：ReLU(x)= max(0, x)</strong></td>
<td></td>
</tr>
<tr>
<td>8)torch.nn.ReLU6</td>
<td>它将用于应用按元素的函数：ReLU6(x)= min(max(0, x), 6)</td>
<td></td>
</tr>
<tr>
<td>9)torch.nn.RReLU</td>
<td>如本文所述, 它将用于逐元素地应用随机泄漏整流线性单位函数：</td>
<td></td>
</tr>
<tr>
<td>10)torch.nn.SELU</td>
<td>它将按以下方式应用按元素的函数：SELU(x)= scale *(max(0, x)+ min(0, a *(exp(x)-1)))这里α= 1.6732632423543772772848170429916717和scale = 1.0507009873554804934193193349852946。</td>
<td></td>
</tr>
<tr>
<td>11)<strong>PyTorch</strong></td>
<td>它将按以下方式应用按元素的功能：</td>
<td></td>
</tr>
<tr>
<td>12)PyTorch</td>
<td>它将按以下方式应用按元素的功能：</td>
<td></td>
</tr>
<tr>
<td>13)torch.nn.Softplus</td>
<td>它将按以下方式应用按元素的功能：</td>
<td></td>
</tr>
<tr>
<td>14)torch.nn.Softshrink</td>
<td>它将按元素应用软收缩功能, 如下所示：</td>
<td></td>
</tr>
<tr>
<td>15)torch.nn.Softsign</td>
<td>它将按以下方式应用按元素的功能：</td>
<td></td>
</tr>
<tr>
<td>16)torch.nn.Tanh</td>
<td>它将按以下方式应用按元素的功能：</td>
<td></td>
</tr>
<tr>
<td>17)torch.nn.Tanhshrink</td>
<td>它将按以下方式应用按元素的函数：Tanhshrink(x)= x-Tanh(x)</td>
<td></td>
</tr>
<tr>
<td>18)torch.nn.Threshold</td>
<td>它将用于阈值输入张量的每个元素。阈值定义为：</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-5-非线性激活函数"><a href="#2-5-非线性激活函数" class="headerlink" title="2.5 非线性激活函数"></a>2.5 非线性激活函数</h4><table>
<thead>
<tr>
<th></th>
<th>非线性激活(其他)</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.Softmin</td>
<td>它用于将softmin函数应用于n维输入张量以重新缩放它们。之后, n维输出Tensor的元素位于0、1的范围内, 且总和为1。Softmin定义为：</td>
<td></td>
</tr>
<tr>
<td>2)<strong>torch.nn.Softmax</strong></td>
<td><strong>它用于将softmax函数应用于n维输入张量以重新缩放它们。之后, n维输出Tensor的元素位于0、1的范围内, 且总和为1。</strong>Softmax定义为：</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.Softmax2d</td>
<td>它用于将SoftMax应用于要素上的每个空间位置。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.LogSoftmax</td>
<td>它用于将LogSoftmax函数应用于n维输入张量。 LofSoftmax函数可以定义为：</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.AdaptiveLogSoftmaxWithLoss</td>
<td>这是训练具有较大输出空间的模型的策略。标签分布高度不平衡时非常有效</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-6-归一化处理"><a href="#2-6-归一化处理" class="headerlink" title="2.6 归一化处理"></a><strong>2.6 归一化处理</strong></h4><table>
<thead>
<tr>
<th></th>
<th>归一化层</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.BatchNorm1d</td>
<td>它用于对2D或3D输入应用批量归一化。</td>
<td></td>
</tr>
<tr>
<td>2)<strong>torch.nn.BatchNorm2d</strong></td>
<td>它用于在4D上应用批量归一化。</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.BatchNorm3d</td>
<td>它用于对5D输入应用批量归一化。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.GroupNorm</td>
<td>它用于在最小输入批次上应用组归一化。</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.SyncBatchNorm</td>
<td>它用于对n维输入应用批量归一化。</td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.InstanceNorm1d</td>
<td>它用于在3D输入上应用实例规范化。</td>
<td></td>
</tr>
<tr>
<td>7)torch.nn.InstanceNorm2d</td>
<td>它用于在4D输入上应用实例规范化。</td>
<td></td>
</tr>
<tr>
<td>8)torch.nn.InstanceNorm3d</td>
<td>它用于在5D输入上应用实例规范化。</td>
<td></td>
</tr>
<tr>
<td>9)torch.nn.LayerNorm</td>
<td>它用于在最小输入批次上应用层归一化。</td>
<td></td>
</tr>
<tr>
<td>10)torch.nn.LocalResponseNorm</td>
<td>它用于对由多个输入平面组成的输入信号进行局部响应归一化, 其中通道占据第二维。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-7-各种损失函数"><a href="#2-7-各种损失函数" class="headerlink" title="2.7 各种损失函数"></a>2.7 各种损失函数</h4><table>
<thead>
<tr>
<th></th>
<th>Loss function</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.L1Loss</td>
<td>它用于衡量输入x和目标y中每个元素之间的平均绝对误差的标准。未减少的损失可描述为：l(x, y)= L = {l1, …, ln}, ln = | xn-yn |, 其中N是批次大小。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.MSELoss</td>
<td>它用于衡量输入x和目标y中每个元素之间的均方误差的标准。未减少的损失可描述为：l(x, y)= L = {l1, …, ln}, ln =(xn-yn)2, 其中N是批次大小。</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.CrossEntropyLoss</td>
<td>此条件将nn.LogSoftmax()和nn.NLLLoss()组合在一个类中。当我们训练C类的分类问题时, 这将很有帮助。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.CTCLoss</td>
<td>连接主义者的时间分类损失计算连续时间序列和目标序列之间的损失。</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.NLLLoss</td>
<td>负对数似然损失用于训练C类的分类问题。</td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.PoissonNLLLoss</td>
<td>目标的Poisson分布为负的对数似然损失-目标(Posson(input)loss(input, target)= input-target * log(target！))</td>
<td></td>
</tr>
<tr>
<td>7)torch.nn.KLDivLoss</td>
<td>这对于连续分布是有用的距离度量, 并且在我们对连续输出分布的空间进行直接回归时也很有用。</td>
<td></td>
</tr>
<tr>
<td>8)torch.nn.BCELoss</td>
<td>它用于创建衡量目标和输出之间的二进制交叉熵的标准。未减少的损失可描述为：l(x, y)= L = {l1, …, ln}, ln = -wn [yn * logxn +(1-yn)* log(1-xn)], 其中N是批次大小。</td>
<td></td>
</tr>
<tr>
<td>9)torch.nn.BCEWithLogitsLoss</td>
<td>它在一个类别中将Sigmoid层和BCELoss结合在一起。通过将操作合并到一层, 我们可以利用log-sum-exp技巧来实现数值稳定性。</td>
<td></td>
</tr>
<tr>
<td>10)torch.nn.MarginRankingLoss</td>
<td>它创建一个标准来测量给定输入x1, x2, 两个1D迷你批量张量和包含1或-1的标签1D迷你批量张量y的损耗。迷你批次中每个样本的损失函数如下：loss(x, y)= max(0, -y *(x1-x2)+ margin</td>
<td></td>
</tr>
<tr>
<td>11)torch.nn.HingeEmbeddingLoss</td>
<td>HingeEmbeddingLoss度量给定输入张量x和包含1或-1的标签张量y的损失。它用于测量两个输入是否相似或不相似。损失函数定义为：</td>
<td></td>
</tr>
<tr>
<td>12)torch.nn.MultiLabelMarginLoss</td>
<td>它用于创建优化输入x和输出y之间的多类多分类铰链损耗的标准。</td>
<td></td>
</tr>
<tr>
<td>13)torch.nn.SmoothL1Loss</td>
<td>它用于创建一个标准, 如果绝对逐项误差低于1, 则使用平方项, 否则使用L1项。也称为胡贝尔损耗：</td>
<td></td>
</tr>
<tr>
<td>14)torch.nn.SoftMarginLoss</td>
<td>它用于创建优化输入张量x和目标张量y之间(包含1或-1)的两类分类逻辑损失的标准。</td>
<td></td>
</tr>
<tr>
<td>15)torch.nn.MultiLabelSoftMarginLoss</td>
<td>它用于创建一个标准, 该标准基于输入x与大小(N, C)的目标y之间的最大熵来优化多标签对所有损失。</td>
<td></td>
</tr>
<tr>
<td>16)torch.nn.CosineEmbeddingLoss</td>
<td>它用于创建一个标准, 该标准测量给定输入张量x1, x2和张量标签y的值为1或-1的损失。它用于使用余弦距离来测量两个输入是相似还是相异。</td>
<td></td>
</tr>
<tr>
<td>17)torch.nn.MultiMarginLoss</td>
<td>它用于创建优化输入x和输出y之间的多类分类铰链损耗的标准。</td>
<td></td>
</tr>
<tr>
<td>18)torch.nn.TripletMarginLoss</td>
<td>它用于创建衡量给定输入张量x1, x2, x3和值大于0的余量的三重态损失的标准。它用于衡量样本之间的相对相似性。三元组由锚点, 正例和负例组成。 L(a, p, n)= max {d(ai, pi)-d(ai, ni)+ margin, 0}</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-8-CNN卷积层"><a href="#2-8-CNN卷积层" class="headerlink" title="2.8 CNN卷积层"></a>2.8 CNN卷积层</h4><table>
<thead>
<tr>
<th></th>
<th>Convolution layers</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.Conv1d</td>
<td>该软件包将用于对由多个输入平面组成的输入信号进行一维卷积。</td>
<td></td>
</tr>
<tr>
<td>2)<strong>torch.nn.Conv2d</strong></td>
<td><strong>该软件包将用于在由多个输入平面组成的输入信号上应用2D卷积。</strong></td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.Conv3d</td>
<td>该软件包将用于在由多个输入平面组成的输入信号上应用3D卷积。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.ConvTranspose1d</td>
<td>该软件包将用于在由多个输入平面组成的输入图像上应用一维转置卷积算符。</td>
<td></td>
</tr>
<tr>
<td>5)<strong>torch.nn.ConvTranspose2d</strong></td>
<td><strong>该软件包将用于在由多个输入平面组成的输入图像上应用2D转置卷积运算符。</strong></td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.ConvTranspose3d</td>
<td>该软件包将用于在由多个输入平面组成的输入图像上应用3D转置卷积运算符。</td>
<td></td>
</tr>
<tr>
<td>7)torch.nn。展开</td>
<td>它用于从成批的输入张量中提取滑动局部块。</td>
<td></td>
</tr>
<tr>
<td>8)PyTorch折叠</td>
<td>它用于将一系列滑动局部块组合成一个大的包含张量。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-9-pooling层"><a href="#2-9-pooling层" class="headerlink" title="2.9 pooling层"></a>2.9 pooling层</h4><table>
<thead>
<tr>
<th></th>
<th>Pooling layers</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.MaxPool1d</td>
<td>它用于在由多个输入平面组成的输入信号上应用一维最大池。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.MaxPool2d</td>
<td>它用于在由多个输入平面组成的输入信号上应用2D max池。</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.MaxPool3d</td>
<td>它用于在由多个输入平面组成的输入信号上应用3D max池。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.MaxUnpool1d</td>
<td>它用于计算MaxPool1d的局部逆。</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.MaxUnpool2d</td>
<td>它用于计算MaxPool2d的局部逆。</td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.MaxUnpool3d</td>
<td>它用于计算MaxPool3d的局部逆。</td>
<td></td>
</tr>
<tr>
<td>7)torch.nn.AvgPool1d</td>
<td>它用于在由多个输入平面组成的输入信号上应用一维平均池。</td>
<td></td>
</tr>
<tr>
<td>8)torch.nn.AvgPool2d</td>
<td>它用于在由多个输入平面组成的输入信号上应用2D平均池。</td>
<td></td>
</tr>
<tr>
<td>9)torch.nn.AvgPool3d</td>
<td>它用于在由多个输入平面组成的输入信号上应用3D平均池。</td>
<td></td>
</tr>
<tr>
<td>10)torch.nn.FractionalMaxPool2d</td>
<td>它用于在由多个输入平面组成的输入信号上应用2D分数最大池化。</td>
<td></td>
</tr>
<tr>
<td>11)torch.nn.LPPool1d</td>
<td>它用于在由多个输入平面组成的输入信号上应用一维功率平均池。</td>
<td></td>
</tr>
<tr>
<td>12)torch.nn.LPPool2d</td>
<td>它用于在由多个输入平面组成的输入信号上应用2D功率平均池。</td>
<td></td>
</tr>
<tr>
<td>13)torch.nn.AdavtiveMaxPool1d</td>
<td>它用于在由多个输入平面组成的输入信号上应用一维自适应最大池化。</td>
<td></td>
</tr>
<tr>
<td>14)torch.nn.AdavtiveMaxPool2d</td>
<td>它用于在由多个输入平面组成的输入信号上应用2D自适应最大池化。</td>
<td></td>
</tr>
<tr>
<td>15)torch.nn.AdavtiveMaxPool3d</td>
<td>它用于在由多个输入平面组成的输入信号上应用3D自适应最大池化。</td>
<td></td>
</tr>
<tr>
<td>16)torch.nn.AdavtiveAvgPool1d</td>
<td>它用于在由多个输入平面组成的输入信号上应用一维自适应平均池。</td>
<td></td>
</tr>
<tr>
<td>17)torch.nn.AdavtiveAvgPool2d</td>
<td>它用于在由多个输入平面组成的输入信号上应用2D自适应平均池。</td>
<td></td>
</tr>
<tr>
<td>18)torch.nn.AdavtiveAvgPool3d</td>
<td>它用于在由多个输入平面组成的输入信号上应用3D自适应平均池。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-10-填充层"><a href="#2-10-填充层" class="headerlink" title="2.10 填充层"></a>2.10 填充层</h4><table>
<thead>
<tr>
<th></th>
<th>填充层</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.ReflectionPad1d</td>
<td>它将使用输入边界的反射填充输入张量。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.ReflactionPad2d</td>
<td>它将使用输入边界的反射来填充输入张量。</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.ReplicationPad1</td>
<td>它将使用输入边界的复制来填充输入张量。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.ReplicationPad2d</td>
<td>它将使用输入边界的复制来填充输入张量。</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.ReplicationPad3d</td>
<td>它将使用输入边界的复制来填充输入张量。</td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.ZeroPad2d</td>
<td>它将用零填充输入张量边界。</td>
<td></td>
</tr>
<tr>
<td>7)torch.nn.ConstantPad1d</td>
<td>它将用恒定值填充输入张量边界。</td>
<td></td>
</tr>
<tr>
<td>8)torch.nn.ConstantPad2d</td>
<td>它将用恒定值填充输入张量边界。</td>
<td></td>
</tr>
<tr>
<td>9)torch.nn.ConstantPad3d</td>
<td>它将用恒定值填充输入张量边界。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-11-RNN网络层"><a href="#2-11-RNN网络层" class="headerlink" title="2.11 RNN网络层"></a>2.11 RNN网络层</h4><table>
<thead>
<tr>
<th></th>
<th>Recurrent layers</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.RNN</td>
<td>它用于将具有tanh或ReLU非线性的多层Elman RNN应用于输入序列。每一层为输入序列中的每个元素计算以下函数：ht = tanh(Wih xt + bih + Whh tt-1 + bhh)</td>
<td></td>
</tr>
<tr>
<td>2)Torch.nn.LSTM</td>
<td>它用于将多层长期短期记忆(LSTM)RNN应用于输入序列。每一层为输入序列中的每个元素计算以下功能：</td>
<td></td>
</tr>
<tr>
<td>3)GNUPyTorch</td>
<td>它用于将多层门控循环单元(GRU)RNN应用于输入序列。每一层为输入序列中的每个元素计算以下功能：</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.RNNCell</td>
<td>它用于将具有tanh或ReLU非线性的Elman RNN单元应用于输入序列。每一层为输入序列中的每个元素计算以下函数：h’= tanh(Wih x + bih + Whh h + bhh)使用ReLU代替tanh</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.LSTMCell</td>
<td>它用于将长短期记忆(LSTM)单元应用于输入序列。每一层为输入序列中的每个元素计算以下函数：其中σ是S型函数, 而*是Hadamard乘积。</td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.GRUCell</td>
<td>它用于将门控循环单元(GRU)单元应用于输入序列。每一层为输入序列中的每个元素计算以下功能：</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-12-Dropout层定义"><a href="#2-12-Dropout层定义" class="headerlink" title="2.12 Dropout层定义"></a>2.12 Dropout层定义</h4><table>
<thead>
<tr>
<th></th>
<th>Dropout layers</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.Dropout</td>
<td>它用于调节和预防神经元的共适应。培训过程中的一个因素会缩放输出。这意味着模块将在评估期间计算身份函数。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.Dropout2d</td>
<td>如果要素图中的相邻像素相关, 则torch.nn.Dropout不会使激活规则化, 并且会降低有效学习率。在这种情况下, torch.nn.Dropout2d()用于促进要素图之间的独立性。</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.Dropout3d</td>
<td>如果要素图中的相邻像素相关, 则torch.nn.Dropout不会使激活规则化, 并且会降低有效学习率。在这种情况下, torch.nn.Dropout2d()用于促进要素图之间的独立性。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.AlphaDropout</td>
<td>它用于在输入上应用Alpha Dropout。 Alpha Dropout是一种Dropout, 可以保持自规范化属性。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-13-Sparse-layers"><a href="#2-13-Sparse-layers" class="headerlink" title="2.13 Sparse layers"></a>2.13 Sparse layers</h4><table>
<thead>
<tr>
<th></th>
<th>Sparse layers</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn嵌入</td>
<td>它用于存储单词嵌入, 并使用索引检索它们。模块的输入是索引列表, 输出是相应的词嵌入。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.EmbeddingBag</td>
<td>它用于计算嵌入的”袋子”的总和或平均值, 而无需实例化中间嵌入。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-14-距离功能"><a href="#2-14-距离功能" class="headerlink" title="2.14 距离功能"></a>2.14 距离功能</h4><table>
<thead>
<tr>
<th></th>
<th>距离功能</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.Cosine相似度</td>
<td>它将返回x1和x2之间的余弦相似度(沿dim计算)。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.PairwiseDistance</td>
<td>它使用p范数计算向量v1, v2之间的成批成对距离：</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-15-可视化层"><a href="#2-15-可视化层" class="headerlink" title="2.15 可视化层"></a>2.15 可视化层</h4><table>
<thead>
<tr>
<th></th>
<th>Vision layers</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.PixelShuffle</td>
<td>用于将形状为(<em>, C×r2, H, W)的张量的元素重新排列为形状为(</em>, C, H×r, W, r)的张量的元素</td>
<td></td>
</tr>
<tr>
<td>2)<strong>torch.nn.Upsample</strong></td>
<td><strong>它用于对给定的多通道1D, 2D或3D数据进行升采样。</strong></td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.upsamplingNearest2d</td>
<td>它用于对由多个输入通道组成的输入信号进行2D最近邻居上采样。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.UpsamplingBilinear2d</td>
<td>用于将二维双线性上采样应用于由多个输入通道组成的输入信号。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-16-并行数据层"><a href="#2-16-并行数据层" class="headerlink" title="2.16 并行数据层"></a>2.16 并行数据层</h4><table>
<thead>
<tr>
<th></th>
<th>DataParallel层(多GPU, 分布式)</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.DataParallel</td>
<td>它用于在模块级别实现数据并行性。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.DistributedDataParallel</td>
<td>它用于实现分布式数据并行性, 它基于模块级别的torch.distributed包。</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.DistributedDataParallelCPU</td>
<td>它用于在模块级别为CPU实现分布式数据并行性。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-17-各种工具"><a href="#2-17-各种工具" class="headerlink" title="2.17 各种工具"></a>2.17 各种工具</h4><table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1)torch.nn.clip_grad_norm_</td>
<td>它用于裁剪可迭代参数的梯度范数。</td>
<td></td>
</tr>
<tr>
<td>2)torch.nn.clip_grad_value_</td>
<td>用于将可迭代参数的梯度范数裁剪为指定值。</td>
<td></td>
</tr>
<tr>
<td>3)torch.nn.parameters_to_vector</td>
<td>用于将参数转换为一个向量。</td>
<td></td>
</tr>
<tr>
<td>4)torch.nn.vector_to_parameters</td>
<td>它用于将一个向量转换为参数。</td>
<td></td>
</tr>
<tr>
<td>5)torch.nn.weight_norm</td>
<td>它用于对给定模块中的参数应用权重归一化。</td>
<td></td>
</tr>
<tr>
<td>6)torch.nn.remove_weight_norm</td>
<td>它用于删除模块的权重归一化和重新参数化。</td>
<td></td>
</tr>
<tr>
<td>7)torch.nn.spectral_norm</td>
<td>它用于将频谱归一化应用于给定模块中的参数。</td>
<td></td>
</tr>
<tr>
<td>8)torch.nn.PackedSequence</td>
<td>它将用于保存打包序列的数据和batch_size的列表。</td>
<td></td>
</tr>
<tr>
<td>9)torch.nn.pack_padded_sequence</td>
<td>它用于打包包含可变长度填充序列的Tensor。</td>
<td></td>
</tr>
<tr>
<td>10)torch.nn.pad_packed_sequence</td>
<td>它用于填充打包的可变长度序列批次。</td>
<td></td>
</tr>
<tr>
<td>11)torch.nn.pad_sequence</td>
<td>它用于填充具有填充值的可变长度张量列表。</td>
<td></td>
</tr>
<tr>
<td>12)torch.nn.pack_sequence</td>
<td>它用于打包可变长度张量的列表</td>
<td></td>
</tr>
<tr>
<td>13)torch.nn.remove_spectral_norm</td>
<td>它用于删除模块的频谱归一化和重新参数化。</td>
<td></td>
</tr>
</tbody></table>
<h4 id="2-18-tensor简介"><a href="#2-18-tensor简介" class="headerlink" title="2.18  tensor简介"></a>2.18  tensor简介</h4><p><strong>在PyTorch中，torch.Tensor是存储和变换数据的主要工具。</strong><br><strong>Tensor与Numpy的多维数组非常相似。</strong><br><strong>Tensor还提供了GPU计算和自动求梯度等更多功能，这些使Tensor更适合深度学习。****</strong></p>
<p>2.创建Tensor<br>2.1 直接创建一个5*3的未初始化的Tensor：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(5,3)</span><br></pre></td></tr></table></figure>


<p>2.2 创建一个5*3的随机初始化的Tensor</p>
<p>torch.rand：返回一个张量，包含了从区间[0,1)的均匀分布中抽取一组随机数，形状由可变参数size定义。<br>原型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.rand(size,out=None,dtype=None,layout=torch.strided,device=None,</span><br><span class="line">requires_grad=False)-&gt;Tensor</span><br></pre></td></tr></table></figure>


<p>举例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(5,3)</span><br></pre></td></tr></table></figure>


<p>torch.randn:返回一个张量，包含了从标准正态分布(Normal distribution)(均值为0，方差为1，即高斯白噪声)中抽取一组随机数，形状由可变参数sizes定义。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(2,3)</span><br></pre></td></tr></table></figure>


<p>2.3 创建全为0的Tensor(指定数据类型)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(5,3,dtype=long)</span><br></pre></td></tr></table></figure>


<p>2.4 根据数据直接创建</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([5.5,3])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.5 tensor.new_ones:返回一个与size大小相同的用1填充的张量;</p>
<p>默认情况下，返回的Tensor具有与此张量相同的torch.dtype和torch.device;</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```</span><br><span class="line">tensor = torch.tensor((), dtype=torch.int32)</span><br><span class="line">tensor.new_ones((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">[ <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>]], dtype=torch.int32)</span><br></pre></td></tr></table></figure>



<p>2.6 torch.rand_like：返回与输入相同大小的张量，该张量由区间[0,1)上均匀的随机数填充。</p>
<p>原型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.rand_like(input,dtype=None,layout=None,device=None,requires_grad=False,</span><br><span class="line">memory_format=torch.preserve_format)-&gt;tensor</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>torch.rand_like(input)相当于torch.rand(input.size(),dtype=input.dtype,layout=input.layout,device=input.device)</p>
<p>举例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand_like(x,dtype=torch.float)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.7 torch.arange:根据（首，尾，步长）生成tensor</p>
<p>2.8 其余tensor的构造函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Tensor(*sizes)    基础构造函数</span><br><span class="line">ones(*sizes)      全1Tensor</span><br><span class="line">zeros(*sizes)     全0Tensor</span><br><span class="line">eye(*sizes)	  对角线为1，其他为0</span><br><span class="line">arange(s,e,step)  从s到e，步长为step</span><br><span class="line">linespace(s,e,steps)  从s到e，均匀切分成steps份</span><br><span class="line">normal(mean,std)/uniform(from,to)  正态分布/均匀分布</span><br><span class="line">randperm(m)	随机排列</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这些创建方法都可以在创建的时候指定数据类型dtype和存放device(cpu/gpu)</p>
<p>3.Tensor的操作<br>2.1 Tensor的加法操作：</p>
<p>加法形式一：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(5, 3)</span><br><span class="line">y = torch.rand(5, 3)</span><br><span class="line">z = x + y</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>加法形式二：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">z=torch.add(x,y)</span><br><span class="line"></span><br><span class="line">result = torch.empty(5, 3)</span><br><span class="line">torch.add(x, y, out=result)</span><br></pre></td></tr></table></figure>

<p>加法形式三：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.2 Tensor的索引操作：</p>
<p>我们还可以使用类似Numpy的索引操作来访问Tensor的一部分。需要注意的是：索引出来的结果与原数据共享内存，也即修改一个，另一个也会跟着修改。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = x[0,:]</span><br><span class="line">y += 1</span><br><span class="line">print(y)</span><br><span class="line">print(x[0,:])</span><br></pre></td></tr></table></figure>


<p>除了常用的索引选择数据之外，PyTorch还提供了一些高级的选择函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">index_select(<span class="built_in">input</span>,dim,index)   <span class="comment">#在指定维度dim上选取过，比如选取某些行，某些列</span></span><br><span class="line">masked_select(<span class="built_in">input</span>,mask)       <span class="comment">#例子如上，a(a&gt;0),使用ByteTensor进行选取</span></span><br><span class="line">non_zero(<span class="built_in">input</span>)                 <span class="comment">#非0元素的下标</span></span><br><span class="line">gather(<span class="built_in">input</span>,dim,index)         <span class="comment">#根据index，在dim维度上选取数据，输出的size与index一样的</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>4.Tensor数据类型的转换<br>使用独立的函数如 int(),float()等进行转换</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">long_tensor = tensor.long()</span><br><span class="line"></span><br><span class="line">features = features.float()</span><br></pre></td></tr></table></figure>


<p>使用torch.type()函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=t1.type(torch.FloatTensor)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用type_as()函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=t1.type_as(t2)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ol start="5">
<li>Tensor的形状修改<br>5.1 view()</li>
</ol>
<p>用view()来改变Tensor的形状：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = x.view(15)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>-1所指的维度可以根据其他的维度推出来</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">z = x.view(-1,5)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意：<br>view()返回的新tensor与源tensor共享内存，实际上就是同一个tensor，也就是更改一个，另一个也会跟着改变。<br>（顾名思义，view()仅仅改变了对这个张量的观察角度）</p>
<p>Pytorch中的Tensor支持包含一百多种操作，包含转置，索引，切片，数学运算，线性代数，随机数等。</p>
<ol start="6">
<li>Tensor的数据转换<br>6.1 item()</li>
</ol>
<p>作用：它可以将一个标量Tensor转换为一个Python number:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(1)</span><br><span class="line">x.item()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>6.2 Tensor 转 NumPy<br>使用numpy()将Tensor转换成NumPy数组：<br>注意，这样产生的NumPy数组与Tensor共享相同的内存，改变其中一个另一个也会改变！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(5)</span><br><span class="line">b = a.numpy() # 转为numpy</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>6.3 NumPy数组转Tensor<br>使用from_numpy()将NumPy数组转换为Tensor：<br>注意，这样产生的NumPy数组与Tensor共享相同的内存，改变其中一个另一个也会改变！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = np.ones(5) </span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ol start="7">
<li>Tensor的广播机制<br>当对两个形状不同的Tensor按元素运算时，可能会触发广播机制(broadcasting)机制：先适当复制元素使这两个Tensor形状相同后再按元素运算。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(1, 3).view(1,2) #[1,2]</span><br><span class="line">y =torch.arange(1, 4).view(3,1)</span><br><span class="line">print(x+y)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[2, 3],</span><br><span class="line"> [3, 4],</span><br><span class="line"> [4, 5]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>8.tensor运算的内存开销<br>索引，view()是不会开辟新的内存的，而像y=x+y这样的运算是会开辟新的内存的，然后y指向新的内存。</p>
<ol start="9">
<li>Tensor ON GPU<br>用方法to()可以将Tensor在CPU和GPU之间相互移动。</li>
</ol>
<p><strong>以下代码只有在PyTorch GPU版本上才会执⾏</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():	</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>)  <span class="comment"># GPU</span></span><br><span class="line">x = torch.arange(<span class="number">1</span>, <span class="number">3</span>).view(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">y = torch.ones_like(x,device=device)  <span class="comment">#直接创建一个在GPU上的Tensor</span></span><br><span class="line"> 	x = x.to(device) <span class="comment"># 等价于 .to(&quot;cuda&quot;)</span></span><br><span class="line">z = x + y</span><br><span class="line"> 	<span class="built_in">print</span>(z)</span><br><span class="line"> 	<span class="built_in">print</span>(z.to(<span class="string">&quot;cpu&quot;</span>, torch.double)) <span class="comment"># to()还可以同时更改数据类型</span></span><br></pre></td></tr></table></figure>



<h3 id="Ski-image"><a href="#Ski-image" class="headerlink" title="Ski-image"></a>Ski-image</h3><h4 id="skimage的简介"><a href="#skimage的简介" class="headerlink" title="skimage的简介"></a>skimage的简介</h4><p>skimage即是Scikit-Image。基于python脚本语言开发的数字图片处理包，比如PIL,Pillow, opencv, scikit-image等。</p>
<p>PIL和Pillow只提供最基础的数字图像处理，功能有限。<br>opencv实际上是一个c++库，只是提供了python接口，更新速度非常慢。<br>scikit-image是基于scipy的一款图像处理包，它将图片作为<strong>numpy数组</strong>进行处理，正好与matlab一样，因此，我们最终选择scikit-image进行数字图像处理。</p>
<p>skimage包的全称是scikit-image SciKit (toolkit for SciPy) ，它对scipy.ndimage进行了扩展，提供了更多的图片处理功能。它是由python语言编写的，由scipy 社区开发和维护。<br>skimage包由许多的子模块组成，各个子模块提供不同的功能。</p>
<h4 id="主要子模块列表如下"><a href="#主要子模块列表如下" class="headerlink" title="主要子模块列表如下"></a>主要子模块列表如下</h4><table>
<thead>
<tr>
<th align="left">子模块名称</th>
<th align="left">主要实现功能</th>
</tr>
</thead>
<tbody><tr>
<td align="left">io</td>
<td align="left">读取、保存和显示图片或视频</td>
</tr>
<tr>
<td align="left">data</td>
<td align="left">提供一些测试图片和样本数据</td>
</tr>
<tr>
<td align="left">color</td>
<td align="left">颜色空间变换</td>
</tr>
<tr>
<td align="left">filters</td>
<td align="left">图像增强、边缘检测、排序滤波器、自动阈值等</td>
</tr>
<tr>
<td align="left">draw</td>
<td align="left">操作于numpy数组上的基本图形绘制，包括线条、矩形、圆和文本等</td>
</tr>
<tr>
<td align="left">transform</td>
<td align="left">几何变换或其它变换，如旋转、拉伸和拉东变换等</td>
</tr>
<tr>
<td align="left">morphology</td>
<td align="left">形态学操作，如开闭运算、骨架提取等</td>
</tr>
<tr>
<td align="left">exposure</td>
<td align="left">图片强度调整，如亮度调整、直方图均衡等</td>
</tr>
<tr>
<td align="left">feature</td>
<td align="left">特征检测与提取等</td>
</tr>
<tr>
<td align="left">measure</td>
<td align="left">图像属性的测量，如相似性或等高线等</td>
</tr>
<tr>
<td align="left">segmentation</td>
<td align="left">图像分割</td>
</tr>
<tr>
<td align="left">restoration</td>
<td align="left">图像恢复</td>
</tr>
<tr>
<td align="left">util</td>
<td align="left">通用函数</td>
</tr>
</tbody></table>
<h3 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h3><h4 id="NumPy-简介"><a href="#NumPy-简介" class="headerlink" title="NumPy- 简介"></a>NumPy- 简介</h4><p>NumPy 是一个 Python 包。 它代表 “Numeric Python”。 它是一个由<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84&spm=1001.2101.3001.7020">多维数组</a>对象和用于处理数组的例程集合组成的库。</p>
<p><strong>Numeric</strong>，即 NumPy 的前身，是由 Jim Hugunin 开发的。 也开发了另一个包 Numarray ，它拥有一些额外的功能。 2005年，Travis Oliphant 通过将 Numarray 的功能集成到 Numeric 包中来创建 NumPy 包。 这个开源项目有很多贡献者。</p>
<h4 id="NumPy-操作"><a href="#NumPy-操作" class="headerlink" title="NumPy 操作"></a>NumPy 操作</h4><p>使用NumPy，开发人员可以执行以下操作：</p>
<ol>
<li>数组的算数和逻辑运算。</li>
<li>傅立叶变换和用于图形操作的例程。</li>
<li>与线性代数有关的操作。 NumPy 拥有线性代数和随机数生成的内置函数。</li>
</ol>
<h4 id="NumPy-Ndarray-对象"><a href="#NumPy-Ndarray-对象" class="headerlink" title="NumPy - Ndarray 对象"></a>NumPy - Ndarray 对象</h4><p>NumPy 中定义的最重要的对象是称为 <code>ndarray</code> 的 N 维数组类型。 它描述相同类型的元素<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E9%9B%86%E5%90%88&spm=1001.2101.3001.7020">集合</a>。 可以使用基于零的索引访问集合中的项目。</p>
<p><code>ndarray</code>中的每个元素在内存中使用相同大小的块。 <code>ndarray</code>中的每个元素是数据类型对象的对象（称为 <code>dtype</code>）。</p>
<p>从<code>ndarray</code>对象提取的任何元素（通过切片）由一个数组标量类型的 Python 对象表示。 下图显示了<code>ndarray</code>，数据类型对象（<code>dtype</code>）和数组标量类型之间的关系。</p>
<p><img src="https://www.tutorialspoint.com//numpy/images/ndarray.jpg" alt="Ndarray"></p>
<p>它从任何暴露数组接口的对象，或从返回数组的任何方法创建一个ndarray。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.array(<span class="built_in">object</span>, dtype = <span class="literal">None</span>, copy = <span class="literal">True</span>, order = <span class="literal">None</span>, subok = <span class="literal">False</span>, ndmin = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>上面的构造器接受以下参数：</p>
<table>
<thead>
<tr>
<th align="left">序号</th>
<th align="left">参数及描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1.</td>
<td align="left"><code>object</code> 任何暴露数组接口方法的对象都会返回一个数组或任何（嵌套）序列。</td>
</tr>
<tr>
<td align="left">2.</td>
<td align="left"><code>dtype</code> 数组的所需数据类型，可选。</td>
</tr>
<tr>
<td align="left">3.</td>
<td align="left"><code>copy</code> 可选，默认为<code>true</code>，对象是否被复制。</td>
</tr>
<tr>
<td align="left">4.</td>
<td align="left"><code>order</code> <code>C</code>（按行）、<code>F</code>（按列）或<code>A</code>（任意，默认）。</td>
</tr>
<tr>
<td align="left">5.</td>
<td align="left"><code>subok</code> 默认情况下，返回的数组被强制为基类数组。 如果为<code>true</code>，则返回子类。</td>
</tr>
<tr>
<td align="left">6.</td>
<td align="left"><code>ndmin</code> 指定返回数组的最小维数。</td>
</tr>
</tbody></table>
<h4 id="NumPy-asarray函数"><a href="#NumPy-asarray函数" class="headerlink" title="NumPy-asarray函数"></a>NumPy-asarray函数</h4><p>此函数类似于<code>numpy.array</code>，除了它有较少的参数。 这个例程对于将 Python 序列转换为<code>ndarray</code>非常有用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.asarray(a, dtype = <span class="literal">None</span>, order = <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>构造器接受下列参数：</p>
<table>
<thead>
<tr>
<th align="left">序号</th>
<th align="left">参数及描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1.</td>
<td align="left"><code>a</code> 任意形式的输入参数，比如列表、列表的元组、元组、元组的元组、元组的列表</td>
</tr>
<tr>
<td align="left">2.</td>
<td align="left"><code>dtype</code> 通常，输入数据的类型会应用到返回的<code>ndarray</code></td>
</tr>
<tr>
<td align="left">3.</td>
<td align="left"><code>order</code> <code>&#39;C&#39;</code>为按行的 C 风格数组，<code>&#39;F&#39;</code>为按列的 Fortran 风格数组</td>
</tr>
</tbody></table>
<p>img.<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=shape&spm=1001.2101.3001.7020">shape</a>[:2] 取彩色图片的长、宽。<br>如果img.shape[:3] 则取彩色图片的长、宽、<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E9%80%9A%E9%81%93&spm=1001.2101.3001.7020">通道</a>。</p>
<p>关于img.shape[0]、[1]、[2]<br>img.shape[0]：图像的垂直尺寸（高度或长度）<br>img.shape[1]：图像的水平尺寸（宽度）<br>img.shape[2]：图像的通道数</p>
<p>在<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E7%9F%A9%E9%98%B5&spm=1001.2101.3001.7020">矩阵</a>中，[0]就表示行数，[1]则表示列数。NumPy - 数据类型</p>
<p>NumPy 支持比 Python 更多种类的数值类型。 下表显示了 NumPy 中定义的不同标量数据类型。</p>
<table>
<thead>
<tr>
<th align="left">序号</th>
<th align="left">数据类型及描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1.</td>
<td align="left"><code>bool_</code> 存储为一个字节的布尔值（真或假）</td>
</tr>
<tr>
<td align="left">2.</td>
<td align="left"><code>int_</code> 默认整数，相当于 C 的<code>long</code>，通常为<code>int32</code>或<code>int64</code></td>
</tr>
<tr>
<td align="left">3.</td>
<td align="left"><code>intc</code> 相当于 C 的<code>int</code>，通常为<code>int32</code>或<code>int64</code></td>
</tr>
<tr>
<td align="left">4.</td>
<td align="left"><code>intp</code> 用于索引的整数，相当于 C 的<code>size_t</code>，通常为<code>int32</code>或<code>int64</code></td>
</tr>
<tr>
<td align="left">5.</td>
<td align="left"><code>int8</code> 字节（-128 ~ 127）</td>
</tr>
<tr>
<td align="left">6.</td>
<td align="left"><code>int16</code> 16 位整数（-32768 ~ 32767）</td>
</tr>
<tr>
<td align="left">7.</td>
<td align="left"><code>int32</code> 32 位整数（-2147483648 ~ 2147483647）</td>
</tr>
<tr>
<td align="left">8.</td>
<td align="left"><code>int64</code> 64 位整数（-9223372036854775808 ~ 9223372036854775807）</td>
</tr>
<tr>
<td align="left">9.</td>
<td align="left"><code>uint8</code> 8 位无符号整数（0 ~ 255）</td>
</tr>
<tr>
<td align="left">10.</td>
<td align="left"><code>uint16</code> 16 位无符号整数（0 ~ 65535）</td>
</tr>
<tr>
<td align="left">11.</td>
<td align="left"><code>uint32</code> 32 位无符号整数（0 ~ 4294967295）</td>
</tr>
<tr>
<td align="left">12.</td>
<td align="left"><code>uint64</code> 64 位无符号整数（0 ~ 18446744073709551615）</td>
</tr>
<tr>
<td align="left">13.</td>
<td align="left"><code>float_</code> <code>float64</code>的简写</td>
</tr>
<tr>
<td align="left">14.</td>
<td align="left"><code>float16</code> 半精度浮点：符号位，5 位指数，10 位尾数</td>
</tr>
<tr>
<td align="left">15.</td>
<td align="left"><code>float32</code> 单精度浮点：符号位，8 位指数，23 位尾数</td>
</tr>
<tr>
<td align="left">16.</td>
<td align="left"><code>float64</code> 双精度浮点：符号位，11 位指数，52 位尾数</td>
</tr>
<tr>
<td align="left">17.</td>
<td align="left"><code>complex_</code> <code>complex128</code>的简写</td>
</tr>
<tr>
<td align="left">18.</td>
<td align="left"><code>complex64</code> 复数，由两个 32 位浮点表示（实部和虚部）</td>
</tr>
<tr>
<td align="left">19.</td>
<td align="left"><code>complex128</code> 复数，由两个 64 位浮点表示（实部和虚部）</td>
</tr>
</tbody></table>
<p>NumPy 数字类型是<code>dtype</code>（数据类型）对象的实例，每个对象具有唯一的特征。 这些类型可以是<code>np.bool_</code>，<code>np.float32</code>等。</p>
<h4 id="np-tile"><a href="#np-tile" class="headerlink" title="np.tile"></a>np.tile</h4><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">np</span>.tile(<span class="class"><span class="keyword">data</span>,(<span class="title">x</span>,<span class="title">y</span>))</span></span><br></pre></td></tr></table></figure>

<p>此函数为扩展函数，data为要扩展的数据，类型为np类型<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%95%B0%E7%BB%84&spm=1001.2101.3001.7020">数组</a>，x,扩展行数，y扩展列数，如下代码测试 </p>
<h4 id="数据类型对象-dtype"><a href="#数据类型对象-dtype" class="headerlink" title="数据类型对象 (dtype)"></a>数据类型对象 (<code>dtype</code>)</h4><p>数据类型对象描述了对应于数组的固定内存块的解释，取决于以下方面：</p>
<ul>
<li>数据类型（整数、浮点或者 Python 对象）</li>
<li>数据大小</li>
<li>字节序（小端或大端）</li>
<li>在结构化类型的情况下，字段的名称，每个字段的数据类型，和每个字段占用的内存块部分。</li>
<li>如果数据类型是子序列，它的形状和数据类型。</li>
</ul>
<h3 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h3><p>Matplotlib 是 Python 的绘图库。 它可与 NumPy 一起使用，提供了一种有效的 MatLab 开源替代方案。 它也可以和图形工具包一起使用，如 PyQt 和 wxPython。在项目中用于绘图，显示图像。</p>
<h4 id="pyplot简介"><a href="#pyplot简介" class="headerlink" title="pyplot简介"></a>pyplot简介</h4><p>pyplot是一个函数集合,能够让matplotlib像matlib一样工作,每一个函数都会对一个figure做出一些改变,例如,创建一个figure,在一个figure里创建一个plotting area,在plotting area里画一些线,在plot里加一些标签等<br> 在pyplot函数调用之间会保留着各种状态,比如当前figure和plotting area和当前的axes(这里的axes是指figure中axes部分,不是指数学上的axis的复数)<br> pyplot API没有面像对象API灵活,这里能看到的大部函数都是从一个Axes对象的方法,建议看文档中的例子了解它是怎么工作的<br> 用pyplot快速创建一张图</p>
<figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;some numbers&#x27;</span>)</span><br><span class="line">plt.<span class="keyword">show</span>()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-a8a66aed541d9e8f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<p>pyplot</p>
<p>为什么x轴是0-3,y轴是1-4,如果你给plot传入一个数组,plot会假设是一个y值的序列,然后自动创建相应的x值,因为python从0开始,默认的x向量与y同样长度,则x为[0,1,2,3]<br> plot是一个万能命令,它可以任意数里的参数,例如,画一个x-y二维图像,可以这样用命令</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt<span class="selector-class">.plot</span>(<span class="selector-attr">[1,2,3,4]</span>,<span class="selector-attr">[1,4,9,16]</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-fb0188d80b4f3427.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<p>plot</p>
<h4 id="规定plot的形式"><a href="#规定plot的形式" class="headerlink" title="规定plot的形式"></a>规定plot的形式</h4><p>对于每个成对的x,y,还有一个可选的第三个参数,用来指定画线的颜色和类型,格式化的字母符号借鉴于matlab,你能把颜色符号与线类型连在一起,默认的格式化符号是’b-‘,就是蓝色的实线,如果你想画一个红色图点,可以</p>
<figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">16</span>],<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.axis([<span class="number">0</span>,<span class="number">6</span>,<span class="number">0</span>,<span class="number">20</span>])</span><br><span class="line">plt.<span class="keyword">show</span>()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-a0204e07203c6cd8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<p>plot</p>
<p>plot文档里有所有的格式化参数,例子中axis()使用一个list [xmin,xmax,ymin,ymax]来指定可见范围<br> 如果matplotlib只能用lists,那对于数字处理就没什么用了.一般来讲,你可以用numpy.array,实际上,所有序列都被内部转换成numpy.array,下面的例子用不同的形式画了一些线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#evenly sampled time at 200ms intervals</span></span><br><span class="line">t = np.arange(<span class="number">0.</span>, <span class="number">5.</span>, <span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#red dashes, blue squares and green triangles</span></span><br><span class="line">plt.plot(t, t, <span class="string">&#x27;r--&#x27;</span>, t, t**<span class="number">2</span>, <span class="string">&#x27;bs&#x27;</span>, t, t**<span class="number">3</span>, <span class="string">&#x27;g^&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-75075bc85daa4794.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<p>plot</p>
<h4 id="使用关键字plotting"><a href="#使用关键字plotting" class="headerlink" title="使用关键字plotting"></a>使用关键字plotting</h4><p>有一些实例,是通过字符串访问变量里的数据,例numpy.recarray,pandas.DataFrame<br> matplotlib可以让你提供一些带有关键字字典的对象,如果是这样的对象,plot可以把字符串和变量关联起来</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">data</span> = &#123;<span class="string">&#x27;a&#x27;</span>: np.arange(<span class="number">50</span>),</span><br><span class="line">        <span class="string">&#x27;c&#x27;</span>: np.random.randint(<span class="number">0</span>, <span class="number">50</span>, <span class="number">50</span>),</span><br><span class="line">        <span class="string">&#x27;d&#x27;</span>: np.random.randn(<span class="number">50</span>)&#125;</span><br><span class="line"><span class="keyword">data</span>[<span class="string">&#x27;b&#x27;</span>] = <span class="keyword">data</span>[<span class="string">&#x27;a&#x27;</span>] + <span class="number">10</span> * np.random.randn(<span class="number">50</span>)</span><br><span class="line"><span class="keyword">data</span>[<span class="string">&#x27;d&#x27;</span>] = np.abs(<span class="keyword">data</span>[<span class="string">&#x27;d&#x27;</span>]) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">plt.scatter(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, c=<span class="string">&#x27;c&#x27;</span>, s=<span class="string">&#x27;d&#x27;</span>, <span class="keyword">data</span>=<span class="keyword">data</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;entry a&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;entry b&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-0d05fd4f5ea8c4ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<p>plot</p>
<p>使用分类变量做图</p>
<p>也可以使用分类变量做图,matlibplot有很多函数可以传入分类变量</p>
<figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">names = [<span class="string">&#x27;group_a&#x27;</span>, <span class="string">&#x27;group_b&#x27;</span>, <span class="string">&#x27;group_c&#x27;</span>]</span><br><span class="line">values = [<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">9</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">plt.bar(names, values)</span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">plt.scatter(names, values)</span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">plt.plot(names, values)</span><br><span class="line">plt.suptitle(<span class="string">&#x27;Categorical Plotting&#x27;</span>)</span><br><span class="line">plt.<span class="keyword">show</span>()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-096048e252dd6eb9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/900/format/webp" alt="img"></p>
<p>plot</p>
<h4 id="控制线属性"><a href="#控制线属性" class="headerlink" title="控制线属性"></a>控制线属性</h4><p>线有很多属性,如线宽,样式,反锯齿,有很多方式设置线的属性</p>
<ul>
<li>用关键字参数设置</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x,y,linewidth=2.0)</span><br></pre></td></tr></table></figure>

<ul>
<li>用line2D实例的setter方法,plot会返回一列Line2D对像,例,line1,line2=plot(x1,y1,x2,y2),下面我们假设只有一条线,也就是返回的列表长度为1,我们元组拆包得到列表的第一个元素</li>
</ul>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">line, = plt.<span class="title function_ invoke__">plot</span>(x, y, <span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">line.<span class="title function_ invoke__">set_antialiased</span>(False) <span class="comment"># turn off antialising</span></span><br></pre></td></tr></table></figure>

<ul>
<li>用setp命令,下面这个例子用一个matlab命令设置一条线的多个属性,setp可以传入一个或一列对象,可以使用关键字设置属性</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lines = plt.plot(x1, y1, x2, y2)</span><br><span class="line"><span class="comment">#use keyword args</span></span><br><span class="line">plt.setp(lines, color=<span class="string">&#x27;r&#x27;</span>, linewidth=2.0)</span><br><span class="line"><span class="comment">#or MATLAB style string value pairs</span></span><br><span class="line">plt.setp(lines, <span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;linewidth&#x27;</span>, 2.0)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Property</th>
<th>Value Type</th>
</tr>
</thead>
<tbody><tr>
<td>alpha</td>
<td>float</td>
</tr>
<tr>
<td>color or c</td>
<td>任何matlibplot颜色</td>
</tr>
</tbody></table>
<p>获取可设置属性的列表,调用setp函数</p>
<figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">69</span>]: lines = plt.<span class="title function_ invoke__">plot</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: plt.<span class="title function_ invoke__">setp</span>(lines)</span><br><span class="line">  alpha: <span class="keyword">float</span></span><br><span class="line">  animated: [True | False]</span><br><span class="line">  antialiased <span class="keyword">or</span> aa: [True | False]</span><br><span class="line">  ...snip</span><br></pre></td></tr></table></figure>

<h4 id="使用多个figure和axes"><a href="#使用多个figure和axes" class="headerlink" title="使用多个figure和axes"></a>使用多个figure和axes</h4><p>Matlab和pyplot,有一个当前figure和当前axes的概念,所有的plot命令都会作用在当前axes上,函数gca()返回当前axes,gcf()返回当前figure<br> 通常,你不用担心这个,因为都在内部处理了这些问题,下面是一个创建两个subplot的脚本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(-t) * np.cos(<span class="number">2</span>*np.pi*t)</span><br><span class="line"></span><br><span class="line">t1 = np.arange(<span class="number">0.0</span>, <span class="number">5.0</span>, <span class="number">0.1</span>)</span><br><span class="line">t2 = np.arange(<span class="number">0.0</span>, <span class="number">5.0</span>, <span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.plot(t1, f(t1), <span class="string">&#x27;bo&#x27;</span>, t2, f(t2), <span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">212</span>)</span><br><span class="line">plt.plot(t2, np.cos(<span class="number">2</span>*np.pi*t2), <span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-e03992000391a66d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<p>plot</p>
<p>这里的的figure()是可选的,因为默认情况自动创建了figure(1),还有如果你不指定任何subplot,会默认创建subplot(111),subplot指定行数,列数,plot序号,plot序号的范围是1到行数乘以列数.如果行列数相乘小于10,参数里的逗号是可选的,因为subplot(211)默认是指subplot(2,1,1)<br> 你可以创建任何数量的subplot和axes,如果你想用axes()命令手动指定axes位置(例如不是一个矩形),你可以用axes([left,bottom,width,height]),这里所有数都是小数(0 to1)<br> 可以多次用一个增长的数当参数调用figure()创建多个figures,当然,每个figure都包括多个subplot和axes</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(<span class="number">1</span>)                <span class="comment"># the first figure</span></span><br><span class="line">plt.subplot(<span class="number">211</span>)             <span class="comment"># the first subplot in the first figure</span></span><br><span class="line">plt.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">plt.subplot(<span class="number">212</span>)             <span class="comment"># the second subplot in the first figure</span></span><br><span class="line">plt.plot([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">2</span>)                <span class="comment"># a second figure</span></span><br><span class="line">plt.plot([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])          <span class="comment"># creates a subplot(111) by default</span></span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>)                <span class="comment"># figure 1 current; subplot(212) still current</span></span><br><span class="line">plt.subplot(<span class="number">211</span>)             <span class="comment"># make subplot(211) in figure1 current</span></span><br><span class="line">plt.title(<span class="string">&#x27;Easy as 1, 2, 3&#x27;</span>) <span class="comment"># subplot 211 title</span></span><br></pre></td></tr></table></figure>

<p>clf()可以清除当前figure,cla()可以清除当前axes,如果你觉得内部状态不好用,你可以用弱状态的面向对象API来代替它<br> 如果你创建了多个figure,你需要注意一件事,figure是在调用close()的时候内存才被释放,删除所有figure,或用窗口管理器关闭窗口是不行的,因为pyplot在close()调用之前会有很多内部引用</p>
<h4 id="使用text"><a href="#使用text" class="headerlink" title="使用text"></a>使用text</h4><p>text()命令可以在任何位置填加文本,xlabel,ylabel和title可以在指定的地方填加文本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mu, sigma = <span class="number">100</span>, <span class="number">15</span></span><br><span class="line">x = mu + sigma * np.random.randn(<span class="number">10000</span>)</span><br><span class="line"><span class="comment">#the histogram of the data</span></span><br><span class="line">n, bins, patches = plt.hist(x, <span class="number">50</span>, density=<span class="number">1</span>, facecolor=<span class="string">&#x27;g&#x27;</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Smarts&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Probability&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Histogram of IQ&#x27;</span>)</span><br><span class="line">plt.text(<span class="number">60</span>, <span class="number">.025</span>, <span class="string">r&#x27;$\mu=100,\ \sigma=15$&#x27;</span>)</span><br><span class="line">plt.axis([<span class="number">40</span>, <span class="number">160</span>, <span class="number">0</span>, <span class="number">0.03</span>])</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-0e24a0bd9eac8169.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<p>plot</p>
<p>所有的text()命令都会返回matplotlib.text.Text实例,和线段一样,你可以在函数里或者setp里用关键字参数自定义属性</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t = plt.xlabel(<span class="string">&#x27;my data&#x27;</span>, fontsize=14, color=<span class="string">&#x27;red&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="文本里用数学表达式"><a href="#文本里用数学表达式" class="headerlink" title="文本里用数学表达式"></a>文本里用数学表达式</h4><p>matplotlib里文本里可以用Tex方程表达式,例如,你想写sigma=15,你可以用Tex表达式,然后用$括起来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">r&#x27;$\sigma_i=15$&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>前面的r很重要,它意味着\是字符串,不要当成python转义符,matplotlib有一个内置的Tex解析器和布局引擎,和自己的数字字体,也就是说可以在跨平台的时候不用安装Tex,如果安装了LaTex和dvipng,也可以用来做输出</p>
<h4 id="注释文本"><a href="#注释文本" class="headerlink" title="注释文本"></a>注释文本</h4><p>text()可以用在axes的任何位置,一个用法就是用来注释,annotate()可以很容易的提供帮助功能,有两个坐标点要考虑,xy和xytext,都是元组形式</p>
<figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line">t = np.arange(<span class="number">0.0</span>, <span class="number">5.0</span>, <span class="number">0.01</span>)</span><br><span class="line">s = np.cos(<span class="number">2</span>*np.pi*t)</span><br><span class="line">line, = plt.plot(t, s, lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.annotate(<span class="string">&#x27;local max&#x27;</span>, xy=(<span class="number">2</span>, <span class="number">1</span>), xytext=(<span class="number">3</span>, <span class="number">1.5</span>),</span><br><span class="line">             arrowprops=dict(facecolor=<span class="string">&#x27;black&#x27;</span>, shrink=<span class="number">0.05</span>),</span><br><span class="line">             )</span><br><span class="line"></span><br><span class="line">plt.ylim(<span class="number">-2</span>, <span class="number">2</span>)</span><br><span class="line">plt.<span class="keyword">show</span>()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-a04eaa4ada419baf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<h4 id="对数和其他非线性的axes"><a href="#对数和其他非线性的axes" class="headerlink" title="对数和其他非线性的axes"></a>对数和其他非线性的axes</h4><p>matplotlib不仅提供线性坐标轴刻度,而且还提供对数和分对数刻度,这种刻度对跨度很大的数据很有用,改变刻度比例很简单:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.xscale(<span class="string">&#x27;log&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>y轴不同刻度的例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> NullFormatter  <span class="comment"># useful for `logit` scale</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Fixing random state for reproducibility</span></span><br><span class="line">np.random.seed(<span class="number">19680801</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># make up some data in the interval ]0, 1[</span></span><br><span class="line">y = np.random.normal(loc=<span class="number">0.5</span>, scale=<span class="number">0.4</span>, size=<span class="number">1000</span>)</span><br><span class="line">y = y[(y &gt; <span class="number">0</span>) &amp; (y &lt; <span class="number">1</span>)]</span><br><span class="line">y.sort()</span><br><span class="line">x = np.arange(<span class="built_in">len</span>(y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot with various axes scales</span></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># linear</span></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.yscale(<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># log</span></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># symmetric log</span></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(x, y - y.mean())</span><br><span class="line">plt.yscale(<span class="string">&#x27;symlog&#x27;</span>, linthreshy=<span class="number">0.01</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;symlog&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># logit</span></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.yscale(<span class="string">&#x27;logit&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;logit&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Format the minor tick labels of the y-axis into empty strings with</span></span><br><span class="line"><span class="comment"># `NullFormatter`, to avoid cumbering the axis with too many labels.</span></span><br><span class="line">plt.gca().yaxis.set_minor_formatter(NullFormatter())</span><br><span class="line"><span class="comment"># Adjust the subplot layout, because the logit one may take more space</span></span><br><span class="line"><span class="comment"># than usual, due to y-tick labels like &quot;1 - 10^&#123;-3&#125;&quot;</span></span><br><span class="line">plt.subplots_adjust(top=<span class="number">0.92</span>, bottom=<span class="number">0.08</span>, left=<span class="number">0.10</span>, right=<span class="number">0.95</span>, hspace=<span class="number">0.25</span>,</span><br><span class="line">                    wspace=<span class="number">0.35</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/16406750-2ed448dea9d4e93b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640/format/webp" alt="img"></p>
<h3 id="pillow（PIL）"><a href="#pillow（PIL）" class="headerlink" title="pillow（PIL）"></a>pillow（PIL）</h3><p>读取图片:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Image.open()</span><br></pre></td></tr></table></figure>

<p>array转换成image:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mage.fromarray(img)</span><br><span class="line">mage.fromarray(img)..resize((HW[<span class="number">1</span>],HW[<span class="number">0</span>])<span class="comment">#获得图片尺寸</span></span><br></pre></td></tr></table></figure>

<h4 id="一、使用-Image-open-创建图像实例"><a href="#一、使用-Image-open-创建图像实例" class="headerlink" title="一、使用 Image.open() 创建图像实例"></a>一、使用 Image.open() 创建图像实例</h4><p><code>Image </code>是 <code>Pillow </code>最常用的类，他可以通过多种方式创建图像实例。</p>
<p>“ from PIL import Image ”导入 Image 模块。然后通过 Image 类中的 open 函数即可载入图像文件, open 函数会自动判断图片格式，只需指定文件位置即可。成功，open 函数返回一个 Image 对象；载入文件失败，则会引起 IOError 异常 。</p>
<h4 id="1-通过文件创建-Image-对象"><a href="#1-通过文件创建-Image-对象" class="headerlink" title="1. 通过文件创建 Image 对象"></a>1. 通过文件创建 Image 对象</h4><p>通过文件创建 <code>Image </code>图像对象是最常用的方法</p>
<p><strong>示例：</strong>通过文件创建 Image 图像对象</p>
<p><img src="E:\MyBlog\public\img\PIL1.png" alt="image-20220522214824113"></p>
<p><strong>代码解读：</strong></p>
<blockquote>
<p>实例属性说明：<br>format 图像格式<br>size 图像的 (宽,高) 元组<br>mode 常见模式，默认 RGB 真彩图像；L 为灰阶图像；CMYK 印刷色彩；RGBA 带透明度的真彩图像；YCbCr 彩色视频格式；LAB L * a * b颜色空间；HSV 等。<br>show() 方法为使用系统默认图片查看器显示图像，一般用于调试；</p>
</blockquote>
<h4 id="2-从打开文件中读取"><a href="#2-从打开文件中读取" class="headerlink" title="2. 从打开文件中读取"></a>2. 从打开文件中读取</h4><p>可以从文件对象读取而不是文件名，但文件对象必须实现<code>read( )</code>，<code>seek( )</code> 和 <code>tell( ) </code>方法，并且是以二进制模式打开。</p>
<p><strong>示例：</strong>从文件对象中读取图像</p>
<p><img src="E:\MyBlog\public\img\PIL2.png" alt="image-20220522214840768"></p>
<h4 id="3-从-string-二进制流中读取"><a href="#3-从-string-二进制流中读取" class="headerlink" title="3. 从 string 二进制流中读取"></a>3. 从 string 二进制流中读取</h4><p><strong>要从字符串数据中读取图像，需使用 io 类：</strong></p>
<p><img src="E:\MyBlog\public\img\PIL3.png" alt="image-20220522214852602"></p>
<blockquote>
<p><strong>注意：</strong>在读取图像 header 之前将文件倒回（使用 seek(0) ）。</p>
</blockquote>
<h4 id="4-从tar文件中读取"><a href="#4-从tar文件中读取" class="headerlink" title="4. 从tar文件中读取"></a>4. 从tar文件中读取</h4><p><img src="E:\MyBlog\public\img\PIL4.png" alt="image-20220522214911541"></p>
<h4 id="二、读写图像"><a href="#二、读写图像" class="headerlink" title="二、读写图像"></a>二、读写图像</h4><h5 id="1-格式转换并保存图像"><a href="#1-格式转换并保存图像" class="headerlink" title="1. 格式转换并保存图像"></a>1. 格式转换并保存图像</h5><p><code>Image </code>模块中的 <code>save </code>函数可以保存图片，除非你指定文件格式，否则文件的扩展名就是文件格式。</p>
<p><img src="E:\MyBlog\public\img\PIL5.png" alt="image-20220522215020974"></p>
<blockquote>
<p><strong>注意：</strong> 如果你的图片mode是RGBA那么会出现异常,因为 RGBA 意思是红色，绿色，蓝色，Alpha 的色彩空间，Alpha 是指透明度。而 JPG 不支持透明度 ，所以要么丢弃Alpha , 要么保存为.png文件。解决方法将图片格式转换：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&quot;RGB&quot;</span>).save(outfile)  <span class="comment"># convert 转换为 RGB 格式，丢弃Alpha</span></span><br></pre></td></tr></table></figure>

<p><code>save() </code>函数有两个参数，如果文件名没有指定图片格式，那么第二个参数是必须的，他指定图片的格式。</p>
<h5 id="2-创建缩略图"><a href="#2-创建缩略图" class="headerlink" title="2. 创建缩略图"></a>2. 创建缩略图</h5><p>创建缩略图 使用 <code>Image.thumbnail( size )</code>, <code>size </code>为缩略图宽长元组。</p>
<p><strong>示例：</strong> 创建缩略图</p>
<p><img src="E:\MyBlog\public\img\PIL6.png" alt="image-20220522215111572"></p>
<blockquote>
<p><strong>注意：</strong> 出现异常，同上一个示例，convert(“RGB”)转换图片mode。</p>
</blockquote>
<blockquote>
<p><strong>注意：</strong>除非必须，Pillow不会解码或栅格数据。当你打开文件，Pillow通过文件头确定文件格式，大小，mode等数据，余下数据直到需要时才处理。这意味着打开文件非常快速，它与文件大小和压缩格式无关。</p>
</blockquote>
<h4 id="三、剪贴，粘贴、合并图像"><a href="#三、剪贴，粘贴、合并图像" class="headerlink" title="三、剪贴，粘贴、合并图像"></a>三、剪贴，粘贴、合并图像</h4><p><code>Image</code>类包含允许您操作图像中的区域的方法。</p>
<p><strong>如：要从图像中复制子矩形图像使用 crop() 方法。</strong></p>
<h5 id="1-从图像复制子矩形"><a href="#1-从图像复制子矩形" class="headerlink" title="1. 从图像复制子矩形"></a>1. 从图像复制子矩形</h5><p><strong>示例：</strong> 截取矩形图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">box = (<span class="number">100</span>, <span class="number">100</span>, <span class="number">400</span>, <span class="number">400</span>)</span><br><span class="line">region = im.crop(box)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>定义box元组，表示图像基于左上角为（0,0）的坐标，<code>box </code>坐标为 (左，上，右，下）。注意，坐标是基于像素。示例中为 300 * 300 像素。</p>
<h5 id="2-处理子矩形并将其粘贴回来"><a href="#2-处理子矩形并将其粘贴回来" class="headerlink" title="2. 处理子矩形并将其粘贴回来"></a>2. 处理子矩形并将其粘贴回来</h5><p><strong>示例：</strong> 在原图上粘贴子矩形图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">region = region.transpose(Image.ROTATE_180) <span class="comment"># 颠倒180度</span></span><br><span class="line">box = (<span class="number">400</span>, <span class="number">400</span>, <span class="number">700</span>, <span class="number">700</span>)  <span class="comment"># 粘贴位置，像素必须吻合，300 * 300</span></span><br><span class="line">im.paste(region, box)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：</strong>将子图（region） 粘贴（paste）回原图时，粘贴位置 box 的像素与宽高必须吻合。而原图和子图的 mode 不需要匹配，Pillow会自动处理。</p>
</blockquote>
<p><strong>示例：</strong>滚动图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">roll</span>(<span class="params">image, delta</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 向侧面滚动图像 &quot;&quot;&quot;</span></span><br><span class="line">    xsize, ysize = image.size</span><br><span class="line"></span><br><span class="line">    delta = delta % xsize</span><br><span class="line">    <span class="keyword">if</span> delta == <span class="number">0</span>: <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">    part1 = image.crop((<span class="number">0</span>, <span class="number">0</span>, delta, ysize))</span><br><span class="line">    part2 = image.crop((delta, <span class="number">0</span>, xsize, ysize))</span><br><span class="line">    image.paste(part1, (xsize - delta, <span class="number">0</span>, xsize, ysize))</span><br><span class="line">    image.paste(part2, (<span class="number">0</span>, <span class="number">0</span>, xsize - delta, ysize))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    image_path = <span class="string">&#x27;test.jpg&#x27;</span></span><br><span class="line">    im = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line">    roll(im, <span class="number">300</span>).show()  <span class="comment"># 向侧面滚动 300 像素</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="3-分离和合并通道"><a href="#3-分离和合并通道" class="headerlink" title="3. 分离和合并通道"></a>3. 分离和合并通道</h5><p><code>Pillow </code>允许处理图像的各个通道，例如RGB图像有R、G、B三个通道。 <code>split </code>方法分离图像通道，如果图像为单通道则返回图像本身。merge 合并函数采用图像的 <code>mode </code>和 通道元组为参数，将它们合并成新图像。</p>
<p><strong>示例：</strong>交换RGB图像的三个波段</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r, g, b = im.split()</span><br><span class="line">im = Image.merge(&quot;RGB&quot;, (b, g, r))</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：</strong>如果要处理单色系，可以先将图片转换为’RGB‘</p>
</blockquote>
<h4 id="四-几何变换"><a href="#四-几何变换" class="headerlink" title="四. 几何变换"></a>四. 几何变换</h4><p><code>PIL.Image.Image </code>包含调整图像大小<code>resize()</code>和旋转 <code>rotate() </code>的方法。前者采用元组给出新的大小，后者采用逆时针方向的角度。</p>
<p><strong>示例：</strong>调整大小并逆时针旋转 45度</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out = im.resize((128, 128))</span><br><span class="line">out = out.rotate(45)</span><br></pre></td></tr></table></figure>

<p>要以90度为单位旋转图像，可以使用<code> rotate()</code> 或 <code>transpose() </code>方法。后者也可用于围绕其水平轴或垂直轴翻转图像。</p>
<p><strong>示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">out = im.transpose(Image.FLIP_LEFT_RIGHT) # 水平左右翻转</span><br><span class="line">out = im.transpose(Image.FLIP_TOP_BOTTOM) # 垂直上下翻转</span><br><span class="line">out = im.transpose(Image.ROTATE_90) # 逆时针90度</span><br><span class="line">out = im.transpose(Image.ROTATE_180) # 逆时针180度</span><br><span class="line">out = im.transpose(Image.ROTATE_270) # 逆时针270度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>rotate() </code>和 <code>transpose()</code> 方法相同，他们之间没有差别， <code>transpose() </code>方法比较通用。</p>
<h4 id="五-颜色变换"><a href="#五-颜色变换" class="headerlink" title="五. 颜色变换"></a>五. 颜色变换</h4><p><strong>示例：</strong>在 <code>mode </code>之间转换</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">im = Image.open(&quot;hopper.ppm&quot;).convert(&quot;L&quot;) # 转换为灰阶图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：</strong>它支持每种模式转换为”L” 或 “RGB”，要在其他模式之间进行转换，必须先转换模式（通常为“RGB”图像）。</p>
</blockquote>
<h4 id="六-图像增强"><a href="#六-图像增强" class="headerlink" title="六. 图像增强"></a>六. 图像增强</h4><h5 id="1-Filters-过滤器"><a href="#1-Filters-过滤器" class="headerlink" title="1. Filters 过滤器"></a>1. Filters 过滤器</h5><p><code>ImageFilter </code>模块有很多预定义的增强过滤器，通过 <code>filter() </code>方法运用。</p>
<p><strong>示例：</strong>使用<code> filter()</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from PIL import ImageFilter</span><br><span class="line">out = im.filter(ImageFilter.DETAIL)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="2-像素点处理"><a href="#2-像素点处理" class="headerlink" title="2. 像素点处理"></a>2. 像素点处理</h5><p><code>point() </code>方法可用于转换图像的像素值（如对比度），在大多数情况下，可以将函数对象作为参数传递格此方法，它根据函数返回值对每个像素进行处理。</p>
<p><strong>示例：</strong>每个像素点扩大1.2倍</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">out = im.point(lambda i: i * 1.2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上述方法可以用简单的表达式进行图像处理，还可以通过组合<code>point()</code>和 <code>paste() </code>对图像的局部区域进行处理 。</p>
<h5 id="3-处理单独通道"><a href="#3-处理单独通道" class="headerlink" title="3. 处理单独通道"></a>3. 处理单独通道</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 将通道分离</span><br><span class="line">source = im.split()</span><br><span class="line"></span><br><span class="line">R, G, B = 0, 1, 2</span><br><span class="line"></span><br><span class="line"># 选择红色小于100的区域</span><br><span class="line">mask = source[R].point(lambda i: i &lt; 100 and 255)</span><br><span class="line"></span><br><span class="line"># 处理绿色</span><br><span class="line">out = source[G].point(lambda i: i * 0.7)</span><br><span class="line"></span><br><span class="line"># 粘贴已处理的通道，红色通道仅限于&lt;100</span><br><span class="line">source[G].paste(out, None, mask)</span><br><span class="line"></span><br><span class="line"># 合并图像</span><br><span class="line">im = Image.merge(im.mode, source)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>注意创建 mask 的语句：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">imout = im.point(lambda i: expression and 255) xxxxxxxxxx imout = im.point(lambda i: expression and 255) imout ``=` `im.point(``lambda` `i: expression ``and` `255``) </span><br></pre></td></tr></table></figure>

<p>对于 and 逻辑判断来说，<code>expression </code>为 <code>False (0) </code>已经能证明整个表达式为 <code>False (0)</code> , 否则还有对后面的结果进行判断。所以 <code>expression </code>为 <code>False (0)</code> 返回 <code>False (0) </code>，<code>expression </code>为 True （本身的结果）是返回后面的 255；</p>
<p>同理对于 or 的逻辑判断，当前面的表达式为 True，返回前面的值；当前面表达式为 False，返回后面表达式的值。</p>
<h4 id="七、高级增强"><a href="#七、高级增强" class="headerlink" title="七、高级增强"></a>七、高级增强</h4><p>其他图像增强功能可以使用 <code>ImageEnhance </code>模块中的类。从图像创建后，可以使用 <code>ImageEnhance </code>快速调整图片的对比度、亮度、饱和度和清晰度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from PIL import ImageEnhance</span><br><span class="line"></span><br><span class="line">enh = ImageEnhance.Contrast(im)  # 创建调整对比度对象</span><br><span class="line">enh.enhance(1.3).show(&quot;增加30%对比度&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>ImageEnhance 方法类型：</strong></p>
<blockquote>
<p>ImageEnhance.Contrast(im) 对比度<br>ImageEnhance.Color(im) 色彩饱和度<br>ImageEnhance.Brightness(im) 亮度<br>ImageEnhance.Sharpness(im) 清晰度</p>
</blockquote>
<h4 id="八、-动态图像"><a href="#八、-动态图像" class="headerlink" title="八、 动态图像"></a>八、 动态图像</h4><p><code>Pillow </code>支持一些动态图像处理（如FLI/FLC，GIF等格式）。TIFF文件同样可以包含数帧图像。</p>
<p>打开动态图像时，PIL 会自动加载序列中的第一帧。你可以使用 <code>seek </code>和 <code>tell </code>方法在不同的帧之间移动。</p>
<p><strong>示例</strong>： 读取动态图像</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">im = Image.open(&quot;animation.gif&quot;)</span><br><span class="line">im.seek(1) # 跳到第二帧</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    while 1:</span><br><span class="line">        im.seek(im.tell()+1)  # tell() 获取当前帧的索引号</span><br><span class="line">except EOFError: # 当读取到最后一帧时，Pillow抛出EOFError异常。</span><br><span class="line">    pass # 结束</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：</strong>有些版本的库中的驱动程序仅允许您搜索下一帧。要回放文件，您可能需要重新打开它。都遇到无法回放的库时，可以使用 for 语句循环实现。</p>
</blockquote>
<p><strong>示例</strong>：<code>for </code>使用 <code>ImageSequence Iterator </code>类遍历动态图像</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from PIL import ImageSequence</span><br><span class="line">for frame in ImageSequence.Iterator(im):</span><br><span class="line">    # ...处理过程...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>示例：</strong>保存动态图像</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">im.save(out, save_all=True, append_images=[im1, im2, ...])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>参数说明：</strong></p>
<blockquote>
<p>out 需要保存到那个文件<br>save_all 为True，保存图像的所有帧。否则，仅保存多帧图像的第一帧。<br>append_images 需要附加为附加帧的图像列表。列表中的每个图像可以是单帧或多帧图像（ 目前只有GIF，PDF，TIFF和WebP支持此功能）。</p>
</blockquote>
<h4 id="九、Postscript-打印"><a href="#九、Postscript-打印" class="headerlink" title="九、Postscript 打印"></a>九、Postscript 打印</h4><p><code>Pillow </code>允许通过 <code>Postscript Printer </code>在图片上添加图像或文字。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">from PIL import PSDraw</span><br><span class="line"></span><br><span class="line">im = Image.open(&quot;test.jpg&quot;)</span><br><span class="line">title = &quot;hopper&quot;</span><br><span class="line">box = (1*72, 2*72, 7*72, 10*72) # in points</span><br><span class="line"></span><br><span class="line">ps = PSDraw.PSDraw() # 默认 sys.stdout</span><br><span class="line">ps.begin_document(title)</span><br><span class="line"></span><br><span class="line"># 画出图像 (75 dpi)</span><br><span class="line">ps.image(box, im, 75)</span><br><span class="line">ps.rectangle(box)</span><br><span class="line"></span><br><span class="line"># 画出标题</span><br><span class="line">ps.setfont(&quot;HelveticaNarrow-Bold&quot;, 36)</span><br><span class="line">ps.text((3*72, 4*72), title)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="十、配置加载器-draft"><a href="#十、配置加载器-draft" class="headerlink" title="十、配置加载器 draft"></a>十、配置加载器 draft</h4><p>某些解码器允许在从文件中读取图像时对其进行操作。这通常可用于创建缩略图时（当速度比质量更重要）加速解码并打印到单色激光打印机（仅需灰阶图像时）。</p>
<p><code>draft() </code>方法操作已打开但尚未加载的图像，使其尽可能匹配给定的模式和大小。它通过重新配置图像解码器来完成。仅适用于JPEG和<code>MPO</code>文件。</p>
<p><strong>示例：</strong>使用 <code>draft() </code>快速解码图像</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">im = Image.open(&#x27;test.jpg&#x27;)</span><br><span class="line">print(&quot;original =&quot;, im.mode, im.size)</span><br><span class="line"></span><br><span class="line">im.draft(&quot;L&quot;, (100, 100))</span><br><span class="line">print(&quot;draft =&quot;, im.mode, im.size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">original = RGB (1920, 1200)</span><br><span class="line">draft = L (240, 150)</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong> 生成的图像与请求的模式和大小可能不完全匹配。要确保图像不大于给定大小，需改用缩略图方法。</p>
<h3 id="argparse"><a href="#argparse" class="headerlink" title="argparse"></a>argparse</h3><p>argparse是python内置的一个用于命令项选项与参数解析的模块。<br> 主要有三个步骤：<br> 1- 创建 ArgumentParser() 对象；<br> 2- 调用 add_argyment() 方法添加参数；<br> 3- 使用 parse_args() 解析添加的参数。</p>
<p><strong>add_argument()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ArgumentParser.add_argument(name <span class="keyword">or</span> flags...[, action][, nargs][, const][, default]</span><br><span class="line">                            [, <span class="built_in">type</span>][, choices][, required][, <span class="built_in">help</span>][,metavar][, dest])</span><br></pre></td></tr></table></figure>

<ul>
<li>name or flags：选项字符串的名字或者列表，例如foo 或者 -f, -foo；</li>
<li>action：命令行遇到参数时的动作，默认值是store。store_const表示赋值为const；append表示将遇到的值存储成列表，也就是如果参数重复则会保存多个值；append_const表示将参数规范中定义的一个值保存到一个列表；count表示存储遇到的次数；此外也可以继承argparse.Action自定义参数解析；</li>
<li>nargs：应该读取的命令行参数个数，可以是具体的数字，或者是？号，当不指定值时对于Positional argument使用default，对于Optional argument使用const；或者是*号，表示0或多个参数；或者是+号，表示1或多个参数；</li>
<li>const：一个在action和nargs选项所需的常量值；</li>
<li>default：不指定参数时的默认值；</li>
<li>type：命令行参数应该被转换成的类型；</li>
<li>choices：参数可允许的值的一个容器；</li>
<li>required：可选参数是否可以省略（仅针对可选参数）；</li>
<li>help：参数的帮助信息，当指定为argparse.SUPPRESS时表示不显示该参数的帮助信息；</li>
<li>metavar：在usage说明中的参数名称，对于必选参数默认就是参数名称（即上面的name or flags），对于可选参数默认是全大写的参数名称；</li>
<li>dest：parse_args()方法返回的对象所添加的属性的名称。默认情况下，对于可选参数选取最长的名称，中划线转换为下划线。</li>
</ul>
<h2 id="图像着色系统的理论支持——计算机图形学、图像处理技术与人工智能的结合"><a href="#图像着色系统的理论支持——计算机图形学、图像处理技术与人工智能的结合" class="headerlink" title="图像着色系统的理论支持——计算机图形学、图像处理技术与人工智能的结合"></a>图像着色系统的理论支持——计算机图形学、图像处理技术与人工智能的结合</h2><h3 id="图像归一化处理"><a href="#图像归一化处理" class="headerlink" title="图像归一化处理"></a>图像归一化处理</h3><p>1.什么是归一化？<br>归一化，Normalization,是指将在一定范围内的数值集合转换为0～1范围内。归一化的目的是控制输入向量的数值范围，不能过大或者过小。因为复杂程序运行本身已经非常耗时，如果数值过大，运行速度会更慢。<br>2.归一化的方法<br>归一化经常经常采用的是</p>
<p><strong>最大最小值归一化</strong></p>
<p><img src="E:\MyBlog\public\img\归一化.png" alt="image-20220522220605716"></p>
<p>x’为归一化之后的数值，x为需要归一化处理的数值</p>
<p><img src="E:\MyBlog\public\img\归一化1.png" alt="image-20220522220615200"></p>
<p><strong>Z-score归一化</strong></p>
<p>Z-score给予原始数据的均值（mean）和标准差（standard deviation）进行数据的归一化，公式如下，意义为数值距离均值有几个标准差，当E(Z)=0，SD(Z)=1，即均值为0，标准差为1，则表示经过处理后的数据符合标准正态分布。</p>
<p><img src="E:\MyBlog\public\img\归一化2.png" alt="image-20220522220715037"></p>
<p>该方法适用大多数类型的数据，但是它是一种中心化方法，会改变原有数据的分布结构，同样也不适用于稀疏数据的处理。</p>
<p><img src="E:\MyBlog\public\img\归一化3.png" alt="image-20220522220723615"></p>
<p><strong>3.图像归一化处理</strong><br>输入图像每个像素值范围是0到255之间的数值，对于计算机来说这个数值太大了，所以像素值归一化处理一般是将像素值除以255，得到0到1之间的数值来进行计算。<strong>在项目中，为了防止图像处理后数值过大，导致程序运行出错，或栈空间不足，所以我们这里也对图像就行了一个规范化处理。</strong></p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p><img src="E:\MyBlog\public\img\卷积4.jpg" alt="img"></p>
<p><strong>积操作其实就是每次取一个特定大小的矩阵<img src="https://www.zhihu.com/equation?tex=F" alt="[公式]">（蓝色矩阵中的阴影部分），然后将其对输入<img src="https://www.zhihu.com/equation?tex=X" alt="[公式]">（图中蓝色矩阵）依次扫描并进行内积的运算过程。</strong>可以看到，阴影部分每移动一个位置就会计算得到一个卷积值（绿色矩阵中的阴影部分），当<img src="https://www.zhihu.com/equation?tex=F" alt="[公式]">扫描完成后就得到了整个卷积后的结果<img src="https://www.zhihu.com/equation?tex=Y" alt="[公式]">（绿色矩阵）。</p>
<p>同时，我们将这个特定大小的矩阵<img src="https://www.zhihu.com/equation?tex=F" alt="[公式]">称为<strong>卷积核</strong>，即convolutional kernel或kernel或filter或detector，它可以是一个也可以是多个；将卷积后的结果<img src="https://www.zhihu.com/equation?tex=Y" alt="[公式]">称为<strong>特征图</strong>，即feature map，并且每一个卷积核卷积后都会得到一个对应的特征图；最后，对于输入<img src="https://www.zhihu.com/equation?tex=X" alt="[公式]">的形状，都会用三个维度来进行表示，即宽（width），高（high）和通道（channel）。例如图1中输入<img src="https://www.zhihu.com/equation?tex=X" alt="[公式]">的形状为<code>[7,7,1]</code>。</p>
<h4 id="多卷积核"><a href="#多卷积核" class="headerlink" title="多卷积核"></a><strong>多卷积核</strong></h4><p>注意，在上面笔者提到了卷积核的个数还可以是多个，那我们为什么需要多个卷积核进行卷积呢？在<strong>上一篇文章</strong>中我们介绍到：<strong>对于一个卷积核，可以认为其具有识别某一类元素（特征）的能力</strong>；而对于一些复杂的数据来说，仅仅只是通过一类特征来进行辨识往往是不够的。因此，通常来说我们都会通过多个不同的卷积核来对输入进行特征提取得到多个特征图，然再输入到后续的网络中。</p>
<p><img src="E:\MyBlog\public\img\卷积5.jpg" alt="img"></p>
<p>图 2. 多卷积核卷积图</p>
<p>如图2所示，对于同一个输入，通过两个不同的卷积核对其进行卷积特征提取，最后便能得到两个不同的特征图。从图2右边的特征图可以发现，上面的特征图在锐利度方面明显会强于下面的特征图。当然，这也是使用多卷积核进行卷积的意义，探测到多种特征属性以有利于后续的下游任务。</p>
<h4 id="卷积的计算"><a href="#卷积的计算" class="headerlink" title="卷积的计算"></a><strong>卷积的计算</strong></h4><p>到此为止， 对于卷积的原理和意义就算是交待完了，并且通过这些动态图片的展示，我们也有了更为直观的了解。但所谓数无形时少直觉，形少数时难入微。因此，下面我们就以单通道（灰度图）和三通道的输入来实际计算一下整个卷积的过程。</p>
<h4 id="单通道单卷积核"><a href="#单通道单卷积核" class="headerlink" title="单通道单卷积核"></a><strong>单通道单卷积核</strong></h4><p>如图3所示，现在有一张形状为<code>[5,5,1]</code>的灰度图，我们需要用图3右边的卷积核对其进行卷积处理，同时再考虑到偏置的作用。那么其计算过程是怎么样的呢？</p>
<p><img src="E:\MyBlog\public\img\卷积6.jpg" alt="img">图 3. 输入与卷积</p>
<p>如图4所示，右边为卷积后的特征图（feature map），左边为卷积核对输入图片左上放进行卷积时的示意图。因此，对于这个部分的计算过程有：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cunderbrace%7B1%5Ccdot0+2%5Ccdot0+0%5Ccdot1-1%5Ccdot0+1%5Ccdot1+0%5Ccdot1+2%5Ccdot1-1%5Ccdot0-2%5Ccdot1%7D_%7Bkernel%7D%5Cunderbrace%7B%5C;%5C;+1%5C;%5C;%7D_%7Bbias%7D=2%5C;%5C;%5C;%5C;%5C;%5C;%5C;%5C;%5C;%5C;%5C;(1)+%5C%5C" alt="[公式]"></p>
<p><img src="E:\MyBlog\public\img\卷积7.jpg" alt="img">图 4. 单通道单卷积（一）</p>
<p>同理，对于最右下角部分卷积计算过程有：</p>
<p><img src="https://www.zhihu.com/equation?tex=2%5Ccdot0+1%5Ccdot0+0%5Ccdot1+0%5Ccdot0+0%5Ccdot1+0%5Ccdot1-1%5Ccdot1+0%5Ccdot0-0%5Ccdot1+1=0%5C;%5C;%5C;%5C;%5C;%5C;%5C;%5C;%5C;%5C;%5C;(2)+%5C%5C" alt="[公式]"></p>
<p><img src="E:\MyBlog\public\img\卷积8.jpg" alt="img">图 5. 单通道单卷积（二）</p>
<p>因此，对于最后卷积的结果，我们得到的将是一个如图5右边所示形状为<code>[3,3,1]</code>的特征图。到此我们就把单通道单卷积的计算过程介绍完了。下面我们再来看单通道多卷积核的例子。</p>
<h4 id="单通道多卷积核"><a href="#单通道多卷积核" class="headerlink" title="单通道多卷积核"></a><strong>单通道多卷积核</strong></h4><p>如图6所示，左边依旧为输入矩阵，我们现在要用右边所示的两个卷积核对其进行卷积处理。</p>
<p><img src="E:\MyBlog\public\img\卷积9.jpg" alt="img"></p>
<p>图 6. 单通道多卷积（一）</p>
<p>同时可以看到，图6中右边的第一个卷积核就是图3里的卷积核，其结果也就是图5中计算得到的结果。对于旁边的卷积核，其计算过程如图7所示：</p>
<p><img src="E:\MyBlog\public\img\卷积10.jpg" alt="img">图 7. 单通道多卷积（二）</p>
<p>最后我们便能得到如图8右边所示的，形状为<code>[3,3,2]</code>的卷积特征图，其中2表示两个特征通道。</p>
<p><img src="E:\MyBlog\public\img\卷积11.jpg" alt="img">图 8. 单通道多卷积结果</p>
<p>到此，对于单通道的卷积计算过程就介绍完了。但通常情况下，我们遇到得更多的就是对多通道的输入进行卷积处理，例如包含有RGB三个通道的彩色图片等。接下来，笔者就开始介绍多通道的卷积计算过程。</p>
<h4 id="多通道单卷积核"><a href="#多通道单卷积核" class="headerlink" title="多通道单卷积核"></a><strong>多通道单卷积核</strong></h4><p>对于多通道的卷积过程，总体上还是还是同之前的一样，都是每次选取特定位置上的神经元进行卷积，然后依次移动直到卷积结束。下面我们先来看看多通道单卷积核的计算过程。</p>
<p><img src="E:\MyBlog\public\img\卷积12.jpg" alt="img">图 9. 多通道单卷积输入</p>
<p>如图9所示，左边为包含有三个通道的输入，右边为一个卷积核和一个偏置。<strong>注意，强调一下右边的仅仅只是一个卷积核，不是三个</strong>。笔者看到不少人在这个地方都会搞错。因为输入是三个通道，所以在进行卷积的时候，对应的每一个卷积核都必须要有三个通道才能进行卷积。下面我们就来看看具体的计算过程。</p>
<p><img src="E:\MyBlog\public\img\卷积3.jpg" alt="img">图 10. 多通道单卷积核图</p>
<p>如图10所示，右边为卷积后的特征图（feature map），左边为一个三通道的卷积核对输入图片左上放进行卷积时的示意图。因此，对于这个部分的计算过程有：</p>
<p><img src="E:\MyBlog\public\img\逆卷积公式.svg" alt="[公式]"></p>
<p>同理，对于其它部分的卷积计算过程也类似于上述计算步骤。由此我们便能得到如图10右边所示卷积后的形状为<code>[3,3,1]</code>的特征图。</p>
<h4 id="多通道多卷积核"><a href="#多通道多卷积核" class="headerlink" title="多通道多卷积核"></a><strong>多通道多卷积核</strong></h4><p>在介绍完多通道单卷积核的计算过程后，我们再来看看多通道多卷积核的计算过程。</p>
<p><img src="E:\MyBlog\public\img\卷积2.jpg" alt="img">图 11. 多通道多卷积核图</p>
<p>如图11所示，左边依旧为输入矩阵，我们现在要用右边所示的<strong>两个卷积核</strong>对其进行卷积处理。同时可以看到，第一个卷积核就是图9中所示的卷积核，其结果如图10所示。对于第二个卷积核，其计算过程也和式子<img src="https://www.zhihu.com/equation?tex=(3)" alt="[公式]">类似，都是将每个通道上的卷积结果进行相加，最后再加上偏置。因此，最后我们便能得到如图12右边所示的，形状为<code>[3,3,2]</code>的卷积特征图，其中2表示两个特征通道。</p>
<p><img src="E:\MyBlog\public\img\卷积1.jpg" alt="img">图 12. 多通道多卷积核结果图</p>
<p>同时，从上面单通道卷积核多通道卷积的计算过程可以发现：</p>
<p>（1）原始输入有多少个通道，其对应的<strong>一个卷积核</strong>就必须要有多少个通道，这样才能与输入进行匹配，也才能完成卷积操作。换句话说，如果输入数据的形状为<code>[n,n,c]</code>，那么对应每个卷积核的通道数也必须为<code>c</code>。</p>
<p>（2）用<code>k</code>个卷积核对输入进行卷积处理，那么最后得到的特征图一定就会包含有<code>k</code>个通道。例如，输入为<code>[n,n,c]</code>，且用<code>k</code>个卷积核对其进行卷积，则卷积核的形状必定为<code>[w1,w2,c,k]</code>，最终得到的特征图形状必定为<code>[h1,h2,k]</code>；其中<code>w1,w2</code>为卷积核的宽度，<code>h1,h2</code>为卷积后特征图的宽度。</p>
<h4 id="为什么需要深度卷积"><a href="#为什么需要深度卷积" class="headerlink" title="为什么需要深度卷积"></a><strong>为什么需要深度卷积</strong></h4><p>所谓深度卷积就是卷积之后再卷积，然后再卷积。卷积的次数可以是几次，也可以是几十次、甚至可以是几百次。因此，在全连接网络中我们可以通过更深的隐藏层来获取到更高级和更抽象的特征，以此来提高下游任务的精度。因此，采用深度卷积也是处于同样的目的。</p>
<h3 id="逆卷积"><a href="#逆卷积" class="headerlink" title="逆卷积"></a>逆卷积</h3><p>核心原理<br><img src="C:\Users\exia\AppData\Roaming\Typora\typora-user-images\image-20220522223526149.png" alt="image-20220522223526149"></p>
<p>最基本的形式</p>
<p><img src="E:\MyBlog\public\img\逆卷积5.gif" alt="img"></p>
<p>如果加入了stride呢？<br><img src="E:\MyBlog\public\img\逆卷积6.png" alt="image-20220522223402713"></p>
<p><img src="E:\MyBlog\public\img\逆卷积4.gif" alt="img"></p>
<p>如果加入了padding呢？</p>
<p><img src="E:\MyBlog\public\img\逆卷积3.png" alt="image-20220522223314572"></p>
<p><img src="E:\MyBlog\public\img\逆卷积2.gif" alt="img"></p>
<p>如果是最一般的形式，即既有padding，又有stride呢？<br><img src="E:\MyBlog\public\img\逆卷积.png" alt="image-20220522223242129"></p>
<h3 id="空洞卷积（Dilated-Convolution）"><a href="#空洞卷积（Dilated-Convolution）" class="headerlink" title="空洞卷积（Dilated Convolution）"></a>空洞卷积（Dilated Convolution）</h3><p><strong>简介</strong><br>空洞卷积也叫扩张卷积或者膨胀卷积，简单来说就是在卷积核元素之间加入一些空格(零)来扩大卷积核的过程。</p>
<p>空洞卷积的简单原理。下图是常规卷积和空洞卷积的动图对比：</p>
<p>常规卷积:</p>
<p><img src="E:\MyBlog\public\img\空洞卷积7.png" alt="image-20220522221806559"></p>
<p>空洞卷积:</p>
<p><img src="E:\MyBlog\public\img\空洞卷积6.png" alt="image-20220522221818309"></p>
<p>假设以一个变量a来衡量空洞卷积的扩张系数，则加入空洞之后的实际卷积核尺寸与原始卷积核尺寸之间的关系：K = K + (k-1)(a-1)</p>
<p>其中k为原始卷积核大小，a为卷积扩张率(dilation rate)，K为经过扩展后实际卷积核大小。除此之外，空洞卷积的卷积方式跟常规卷积一样。我们用一个扩展率a来表示卷积核扩张的程度。比如说a=1,2,4的时候卷积核核感受野如下图所示：</p>
<p><img src="E:\MyBlog\public\img\空洞卷积5.png" alt="image-20220522221830388"></p>
<p>在这张图像中，3×3 的红点表示经过卷积后，输出图像是 3×3 像素。尽管所有这三个扩张卷积的输出都是同一尺寸，但模型观察到的感受野有很大的不同。当a=1，原始卷积核size为3 * 3，就是常规卷积。a=2时，加入空洞之后的卷积核：size=3+(3-1) * (2-1)=5，对应的感受野可计算为：(2 ^(a+2))-1=7。a=3时，卷积核size可以变化到3+(3-1)(4-1)=9，感受野则增长到 (2 ^(a+2))-1=15。有趣的是，与这些操作相关的参数的数量是相等的。我们「观察」更大的感受野不会有额外的成本。因此，扩张卷积可用于廉价地增大输出单元的感受野，而不会增大其核大小，这在多个扩张卷积彼此堆叠时尤其有效。</p>
<p>论文《Multi-scale context aggregation by dilated convolutions》的作者用多个扩张卷积层构建了一个网络，其中扩张率 a 每层都按指数增大。由此，有效的感受野大小随层而指数增长，而参数的数量仅线性增长。这篇论文中扩张卷积的作用是系统性地聚合多个比例的形境信息，而不丢失分辨率。这篇论文表明其提出的模块能够提升那时候（2016 年）的当前最佳形义分割系统的准确度。请参阅论文了解更多信息。</p>
<p>为什么要增大感受野？<br>这里涉及到语义分割的一些发展历程，之前FCN率先提出以全卷积方式来处理像素级别的分割任务时，包括后来奠定语义分割baseline地位的U-Net，网络结构中存在大量的池化层来进行下采样，大量使用池化层的结果就是损失掉了一些信息，在解码上采样重建分辨率的时候肯定会有影响。特别是对于多目标、小物体的语义分割问题，以U-Net为代表的分割模型一直存在着精度瓶颈的问题。而基于增大感受野的动机背景下就提出了以空洞卷积为重大创新的deeplab系列分割网络。如下图所示：</p>
<p><img src="E:\MyBlog\public\img\空洞卷积4.png" alt="image-20220522221852291"></p>
<p>如何计算CNN的感受野<br>感受野(Receptive Field)是CNN中最重要的基础概念之一。深入理解感受野对于一些任务的网络结构设计和优化有着重要意义，比如语义分割模型的空洞卷积，其中就涉及到对感受野的深刻理解。</p>
<p>所谓感受野，是指输出特征图上某个像素对应到输入空间中的区域范围。所以感受野可以理解为特征图像素到输入区域的映射。 先来回顾一个从输入到特征图的计算过程：</p>
<p><img src="E:\MyBlog\public\img\空洞卷积3.png" alt="image-20220522221902462"></p>
<p>其中n_in为输入size，p为padding大小，f为卷积核size，s为卷积步长。假设输入大小为5 * 5，f=3 * 3，padding为1 * 1，卷积步长为2 * 2，那么输出特征图size根据公式可计算为3 * 3。如下图所示：</p>
<p><img src="C:\Users\exia\AppData\Roaming\Typora\typora-user-images\image-20220522221913628.png" alt="image-20220522221913628"></p>
<p>然后我们继续对3 * 3的特征图执行卷积，卷积参数同第一次卷积一样，可得输出特征图size为2 * 2。我们把输入、两次卷积过程和对应特征图放到一起看一下：</p>
<p><img src="E:\MyBlog\public\img\空洞卷积1.png" alt="image-20220522221929373"></p>
<p>可以看到两次卷积的特征图分别对应到输入空间的感受野大小，第一次卷积对应关系如图中绿色线条所示，感受野大小为3 * 3，第二次卷积对应关系如图中黄色线条所示，感受野大小为7 * 7。所以关键问题是特征图和输入空间的对应关系中，感受野的大小是如何计算的？</p>
<p>下面我们给出感受野大小的计算公式：</p>
<p><img src="E:\MyBlog\public\img\空洞卷积2.png" alt="image-20220522221939176"></p>
<p>其中RF_l+1为当前特征图对应的感受野大小，也就是我们要计算的目标感受野，RF_l为上一层特征图对应的感受野大小，f_l+1为当前卷积层卷积核大小，最后一项连乘项则表示之前卷积层的步长乘积。</p>
<p>根据感受野的计算公式我们来看上图中两次卷积的感受野计算过程：</p>
<p>原始输入size为5 * 5，第一层卷积核为3 * 3，输入步长为1，输入层初始化感受野为1 * 1，根据公式计算可得第一层卷积后的特征图对应的输入空间的感受野大小为1+(3-1) * 1=3。</p>
<p>第一层卷积输出特征图的感受野size为3，第二层卷积核size为3，卷积步长为2，则第二层的的感受野size计算为3+(3-1) * 2 * 1=7。所以我们可以看到当前层特征图的感受野大小对应到输入空间与前层的感受野和卷积步长以及当前层的卷积核大小密切相关。当步长大于1时，感受野的大小会呈现指数级增长。</p>
<p><img src="E:\MyBlog\public\img\空洞卷积.png" alt="image-20220522221951383"></p>
<p>注意： 感受野还有一点比较重要的是，对于一个卷积特征图而言，感受野中每个像素并不是同等重要的，越接近感受野中间的像素相对而言就越重要。</p>
<p>空洞卷积主要有三个作用：<br>扩大感受野。但需要明确一点，池化也可以扩大感受野，但空间分辨率降低了，相比之下，空洞卷积可以在扩大感受野的同时不丢失分辨率，且保持像素的相对空间位置不变。简单而言，空洞卷积可以同时控制感受野和分辨率。</p>
<p>获取多尺度上下文信息。当多个带有不同dilation rate的空洞卷积核叠加时，不同的感受野会带来多尺度信息，这对于分割任务是非常重要的。</p>
<p>可以降低计算量，不需要引入额外的参数，如上图空洞卷积示意图所示，实际卷积时只有带有红点的元素真正进行计算。</p>
<h3 id="RGB与LAB颜色空间的转换"><a href="#RGB与LAB颜色空间的转换" class="headerlink" title="RGB与LAB颜色空间的转换"></a>RGB与LAB颜色空间的转换</h3><h4 id="RGB"><a href="#RGB" class="headerlink" title="RGB"></a>RGB</h4><p>   RGB颜色空间是一种大的分类，具体而言RGB空间还包含多种空间，其中sRGB是HP和Microsoft联合制定的标准RGB空间，除此之外还有Adobe RGB，Apple RGB，ColorMatch RGB等等，他们通过不同的方式表示RGB三种颜色，使得它们具有不同的色彩宽度。<br>   计算机色彩显示器显示色彩的原理与彩色电视机一样，都是采用R、G、B相加混色的原理，通过发射出三种不同强度的电子束，使屏幕内侧覆盖的红、绿、蓝磷光材料发光而产生色彩的。这种色彩的表示方法称为RGB色彩空间表示。在多媒体计算机技术中，用的最多的是RGB色彩空间表示。<br>   根据三基色原理，用基色光单位来表示光的量，则在RGB色彩空间，任意色光F都可以用 RGB三色不同分量的相加混合而成：<br><img src="E:\MyBlog\public\img\rgb公式.png" alt="image-20220522222128214"></p>
<p>  我们可知自然界中任何一种色光都可由R、G、B三基色按不同的比例相加混合而成，当三基色分量都为0（最弱）时混合为黑色光；当三基色分量都为k（最强）时混合为白色光。任意色彩F是这个立方体坐标中的一点，调整三色系数r、g、b中的任一系数都会改变F的坐标值，也即改变了F的色值。RGB色彩空间采用物理三基色表示，因而物理意义很清楚，适合彩色显象管工作。然而这一体制并不适应人的视觉特点。因而，产生了其它不同的色彩空间表示法。</p>
<p><img src="E:\MyBlog\public\img\rgb.png" alt="image-20220522222138104"></p>
<h4 id="LAB"><a href="#LAB" class="headerlink" title="LAB"></a>LAB</h4><p>  RGB模式是一种发光屏幕的加色模式，CMYK模式是一种颜色反光的印刷减色模式。而Lab模式既不依赖光线，也不依赖于颜料，它是CIE组织确定的一个理论上包括了人眼可以看见的所有色彩的色彩模式。Lab模式弥补了RGB和CMYK两种色彩模式的不足。<br>　　Lab模式由三个通道组成，但不是R、G、B通道。它的一个通道是亮度，即L，取值范围是[0,100],表示从纯黑到纯白。另外两个是色彩通道，用A和B来表示。A通道包括的颜色是从深绿色（底亮度值）到灰色（中亮度值）再到亮粉红色（高亮度值），取值范围是[127,-128]；B通道则是从亮蓝色（底亮度值）到灰色（中亮度值）再到黄色（高亮度值），取值范围是[127,-128]。因此，这种色彩混合后将产生明亮的色彩。<br>　　Lab模式所定义的色彩最多，且与光线及设备无关</p>
<p>用处</p>
<p><img src="E:\MyBlog\public\img\LAB.png" alt="image-20220522224357912"></p>
<p>  在 Adobe Photoshop图像处理软件中，TIFF格式文件中，PDF文档中，都可以见到Lab颜色空间的身影。而在计算机视觉中，尤其是颜色识别相关的算法设计中，rgb,hsv,lab颜色空间混用更是常用的方法。</p>
<h3 id="pre-trained模型的使用"><a href="#pre-trained模型的使用" class="headerlink" title="pre-trained模型的使用"></a>pre-trained模型的使用</h3><p>预训练的模型通过将其权重和偏差矩阵传递给新模型来共享他们的学习成果。</p>
<ol>
<li>当数据集小的时候：</li>
</ol>
<p>A、相似度高：如果训练数据和pretrained <a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=model&spm=1001.2101.3001.7020">model</a>所用的数据相似度较高的时候，我们不需要从头造轮子，只需要修改最后的输出的softmax即可，采用已经训练好的结构来提取特征。</p>
<p>B、相似度低：如果训练数据和pretrained model所用的数据相似度较低，假设网络一共有n层，我们可以冻结预训练模型中的前k个层中的权重，然后重新训练后面的n-k个层，并修改最后一层的<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E5%88%86%E7%B1%BB%E5%99%A8&spm=1001.2101.3001.7020">分类器</a>的输出类即可。因为数据的相似度不高，重新训练的过程就变得非常关键。而新数据集大小的不足，则是通过冻结预训练模型的前k层进行弥补。（相似度不高的时候重新训练是很有必要的，而冻结前K层的原因是为了弥补训练数据量不充足，当然了数据量不足可以采取数据增强方法，比如：对称，旋转，随机切，扭曲等等）</p>
<p>2.当<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E9%9B%86&spm=1001.2101.3001.7020">数据集</a>大的时候：</p>
<p>A、相似度高：这个是非常好也非常难得的情况，此时只要采用pretrained模型不需要改变任何参数即可，即保持模型原有的结构和初始权重不变，随后在新数据集的基础上重新训练。</p>
<p>B、相似度低：因为我们有一个很大的数据集，所以神经网络的训练过程将会比较有效率。然而，因为实际数据与预训练模型的训练数据之间存在很大差异，采用预训练模型将不会是一种高效的方式。因此最好的方法还是将预处理模型中的权重全都初始化后在新数据集的基础上重头开始训练。</p>
<h3 id="网络训练的流程"><a href="#网络训练的流程" class="headerlink" title="网络训练的流程"></a>网络训练的流程</h3><p>网络的训练过程如下：</p>
<p>选定训练组，从样本集中分别随机地寻求N个样本作为训练组；</p>
<p>将各权值、阈值，置成小的接近于0的随机值，并初始化精度控制参数和学习率；</p>
<p>从训练组中取一个输入模式加到网络，并给出它的目标输出向量；</p>
<p>计算出中间层输出向量，计算出网络的实际输出向量；</p>
<p>将输出向量中的元素与目标向量中的元素进行比较，计算出输出误差；对于中间层的隐单元也需要计算出误差；</p>
<p>依次计算出各权值的调整量和阈值的调整量；</p>
<p>调整权值和调整阈值；</p>
<p>当经历M后，判断指标是否满足精度要求，如果不满足，则返回(3)，继续迭代；如果满足就进入下一步；</p>
<p>训练结束，将权值和阈值保存在文件中。这时可以认为各个权值已经达到稳定，分类器已经形成。再一次进行训练，直接从文件导出权值和阈值进行训练，不需要进行初始化。<br>可参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/jiaoyangwm/article/details/80011656?spm=1001.2014.3001.5506">卷积神经网络超详细介绍</a></p>
<h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>1、二维最大池化</p>
<p>返回滑动窗口中的最大值</p>
<p><img src="E:\MyBlog\public\img\池化.png" alt="image-20220522221613200"></p>
<p>2、填充、步幅、和多个通道</p>
<p>池化层与卷积层类似，都具有填充和步幅；</p>
<p>没有可学习的参数；</p>
<p>在每个输入通道应用池化层以获得相应的输出通道；</p>
<p>输出通道数=输入通道数；</p>
<p>3、平均池化层</p>
<p>最大池化层：每个窗口中最强的模式信号</p>
<p>平均池化层：将最大池化层中的最大操作替换为平均；</p>
<p>4、总结</p>
<p>池化层返回窗口中最大或平均值；</p>
<p>缓解卷积层对位置的敏感性；</p>
<p>同样有窗口大小、填充和步幅作为超参数。</p>
<h3 id="自监督介绍"><a href="#自监督介绍" class="headerlink" title="自监督介绍"></a>自监督介绍</h3><p>一句话总结，传统的<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6&spm=1001.2101.3001.7020">深度</a>学习需要大量的人工标注数据，自监督学习通过pretext task（前置任务）学习数据内部分布，生成伪标签来训练模型，打破了标签数据的局限，更接近人工智能的本质。预测图像的颜色，本质是学习图像的语义特征。</p>
<p>为什么这么说，就是站在人类认知的角度，我们为什么看到一张参天大树的图像，可以判断它是直立的？因为我们知道天空和地面的上下位置关系，树的常见状态我们也知道，所以我们能不假思索地判断出来。预测图片拼图和上色也是一样，我们学习到了图像的语义特征信息。而自监督学习可以不需要人为的标签标注，也是充分学习了图像的内部数据的结果。</p>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><h4 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h4><p>对一个Gray的图片建立到RGB的映射模型是一个比较复杂的回归问题，且效果难以把控。所以这里提出使用Lab颜色空间作为整个模型的映射机制，由于Lab将色彩信息放置在ab两个通道的特性，而L通道仅保存亮度等信息，这些信息可以从Gray图直接得到。</p>
<p>这就是说模型的输入是Lab中L通道的矩阵，目标是一个ab两通道的二层矩阵，建立的是从L向ab的映射关系。</p>
<p>当得到ab通道的信息再组合上L通道信息即得到彩色的Lab图片，而Lab图片到RGB图片的转换是固定的，也就是说，得到了期待的彩色RGB图片。</p>
<h4 id="前期优化"><a href="#前期优化" class="headerlink" title="前期优化"></a>前期优化</h4><p>那么，对训练过程中的一张图片，得到它的L信息很容易，得到ab信息也很容易，但是Lab色彩空间有个很大的问题就是其中包含了很多人类不可见的色彩，这些色彩是干扰模型预测的要素。在此，提出来一种新的思路，选取数据集中常见的色彩，组成ab值对，作为ab通道的信息。</p>
<p>实验证明，这种思路很成功，最后一共得到了313个常用值对信息。这就是说，预测的目标变为了一个值对或者313个值对的概率分布，原来复杂的回归变成了一个简单不少的分类问题。</p>
<p>当然，这里有一个问题，那就是训练时对于每个RGB图片（转为Lab图片），如何得到其目标的ab值对？这里使用了5近邻搜索法得到像素点的ab值对。</p>
<h4 id="后续处理"><a href="#后续处理" class="headerlink" title="后续处理"></a>后续处理</h4><p>得到了313个ab值对的颜色概率，如何将其映射回ab通道的色彩呢，在尝试了平均法和分立法之后（前者上色过于融合后者过于分界），使用兼有两种要求的模拟退火搜索法得到ab两个通道的矩阵。</p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>事实上，优化函数的研究这些年已经有了很大的发展，Adam已经可以满足本项目的需求了，但是在尝试使用分类经典的交叉熵函数时发现训练的模型上色均比较暗淡，这是因为imagenet数据集的图片普遍比较背景暗淡，为了产生比较鲜艳的色彩，提出了加上颜色再平衡系数的交叉熵函数，训练的模型效果得以改善。</p>
<h4 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h4><p>本项目模型构建基于Keras Function API（TensorFlow后端），训练与Tesla T4 16G GPU。模型提供于Github，可以使用Netron可视化h5模型。修改的交叉熵函数可见于脚本目录下的loss_function.py文件。</p>
<h4 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h4><p>由于图像的颜色具有多模态性质，即一张图像的颜色可以有多种可能，因此<strong>文章不是重建图像颜色，而是预测图像颜色</strong>。</p>
<p>（用灰度图中物体的纹理、语义等信息作为线索，来预测可能的上色，最后的上色结果只要真实即可。这不仅降低了上色的难度，而且也符合人们的认知）颜色预测是一个多模的问题，一个物体本来就可以上不同的颜色。对这种多模性建模，为各个像素预测一个颜色的分布，这可以鼓励探索颜色的多样性，而不仅仅局限在某一种颜色中。人的目标只是优化预测结果和真实图片（ground truth）间的欧氏距离（即MSE）（L2范式），这种损失函数会把所有的颜色求平均（因为颜色具有多模态），从而导致颜色饱和度不高，色彩不丰富。</p>
<p>我们的基本思路，就是通过前向encoder+ 反向decoder+ab概率分布预测的网络结构</p>
<p>代码的模型我们主要模仿的是以下思路编写的：</p>
<p><img src="C:\Users\exia\AppData\Roaming\Typora\typora-user-images\image-20220522223833755.png" alt="image-20220522223833755"></p>
<p>也就是读取图像后，经过一系列卷积，细化图像的精读，增加鲁棒性，接着再通过逆卷积，将图像进行还原，归一化，及统一规格后，将原本rgb颜色空间变为lab空间后，我们通过训练，得到一个深度预测ab通道普遍试用而稳定的权重等参数，构成模型，利用模型为图像着色。</p>
<h2 id="代码解说"><a href="#代码解说" class="headerlink" title="代码解说"></a>代码解说</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#__init__.py：</span><br><span class="line"># 定义并初始化网络，在初始化方法中引入父类初始化方法</span><br><span class="line">from .base_color import *</span><br><span class="line">from .eccvmodel import *</span><br><span class="line">from .siggraph17 import *</span><br><span class="line">from .util import *</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#base_color.py：</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">#在这里我们开始训练数据集，做图像处理中归一化处理，限制在一定范围内，防止数据过大，方便处理，增加鲁棒性</span><br><span class="line"></span><br><span class="line">from torch import nn</span><br><span class="line">#继承nn.Module,自定义网络模型，也可以根据需求对经典模型进行调整，他们都继承共同的抽象类nn.Module,其中包含好了很多函数。</span><br><span class="line">class BaseColor(nn.Module):</span><br><span class="line"># self相当于java，c++的this</span><br><span class="line">	def __init__(self):</span><br><span class="line">		#继承构造函数</span><br><span class="line">		#super() 函数是用于调用父类(超类)的一个方法</span><br><span class="line">		super(BaseColor, self).__init__()</span><br><span class="line"></span><br><span class="line">		self.l_cent = 50.#中心</span><br><span class="line">		self.l_norm = 100.#原灰度图归一化</span><br><span class="line">		self.ab_norm = 110.#预测的彩色，图片进行归一化</span><br><span class="line"></span><br><span class="line">	def normalize_l(self, in_l):</span><br><span class="line">		return (in_l-self.l_cent)/self.l_norm</span><br><span class="line"></span><br><span class="line">	def unnormalize_l(self, in_l):</span><br><span class="line">		return in_l*self.l_norm + self.l_cent</span><br><span class="line"></span><br><span class="line">	def normalize_ab(self, in_ab):</span><br><span class="line">		return in_ab/self.ab_norm</span><br><span class="line"></span><br><span class="line">	def unnormalize_ab(self, in_ab):</span><br><span class="line">		return in_ab*self.ab_norm</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line">#神经网络模型1</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import numpy as np</span><br><span class="line">from IPython import embed</span><br><span class="line"></span><br><span class="line">from .base_color import *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义网络结构，一共有8层conv网络层</span><br><span class="line"># 每一层conv都有二维卷积块和relu块，最后以BatchNorm layer结束</span><br><span class="line">class ECCVGenerator(BaseColor):</span><br><span class="line">    #nn.BatchNorm2d()</span><br><span class="line">    # 卷积层之后总会添加BatchNorm2d进行数据的归一化处理，这使得数据在进行Relu之前不会因为数据过大而导致网络性能的不稳定。</span><br><span class="line">    def __init__(self, norm_layer=nn.BatchNorm2d):</span><br><span class="line">        super(ECCVGenerator, self).__init__()</span><br><span class="line"></span><br><span class="line">        model1=[nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model1+=[nn.ReLU(True),]</span><br><span class="line">        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True),]</span><br><span class="line">        model1+=[nn.ReLU(True),]</span><br><span class="line">        model1+=[norm_layer(64),]</span><br><span class="line"></span><br><span class="line">        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model2+=[nn.ReLU(True),]</span><br><span class="line">        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True),]</span><br><span class="line">        model2+=[nn.ReLU(True),]</span><br><span class="line">        model2+=[norm_layer(128),]</span><br><span class="line"></span><br><span class="line">        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model3+=[nn.ReLU(True),]</span><br><span class="line">        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model3+=[nn.ReLU(True),]</span><br><span class="line">        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=True),]</span><br><span class="line">        model3+=[nn.ReLU(True),]</span><br><span class="line">        model3+=[norm_layer(256),]</span><br><span class="line"></span><br><span class="line">        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model4+=[nn.ReLU(True),]</span><br><span class="line">        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model4+=[nn.ReLU(True),]</span><br><span class="line">        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model4+=[nn.ReLU(True),]</span><br><span class="line">        model4+=[norm_layer(512),]</span><br><span class="line">        # 第5层和第6层dilation=2，采用了空洞卷积</span><br><span class="line">        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model5+=[nn.ReLU(True),]</span><br><span class="line">        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model5+=[nn.ReLU(True),]</span><br><span class="line">        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model5+=[nn.ReLU(True),]</span><br><span class="line">        model5+=[norm_layer(512),]</span><br><span class="line"></span><br><span class="line">        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model6+=[nn.ReLU(True),]</span><br><span class="line">        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model6+=[nn.ReLU(True),]</span><br><span class="line">        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model6+=[nn.ReLU(True),]</span><br><span class="line">        model6+=[norm_layer(512),]</span><br><span class="line"></span><br><span class="line">        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model7+=[nn.ReLU(True),]</span><br><span class="line">        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model7+=[nn.ReLU(True),]</span><br><span class="line">        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model7+=[nn.ReLU(True),]</span><br><span class="line">        model7+=[norm_layer(512),]</span><br><span class="line">        #ConvTranspose2d，逆卷积操作，步长(Stride)，还原成原图</span><br><span class="line">        model8=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True),]</span><br><span class="line">        model8+=[nn.ReLU(True),]</span><br><span class="line">        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model8+=[nn.ReLU(True),]</span><br><span class="line">        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model8+=[nn.ReLU(True),]</span><br><span class="line">        # 最后一层对应到图中红色的方块区域，256到313的量化分布</span><br><span class="line">        model8+=[nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True),]</span><br><span class="line"></span><br><span class="line">        self.model1 = nn.Sequential(*model1)</span><br><span class="line">        self.model2 = nn.Sequential(*model2)</span><br><span class="line">        self.model3 = nn.Sequential(*model3)</span><br><span class="line">        self.model4 = nn.Sequential(*model4)</span><br><span class="line">        self.model5 = nn.Sequential(*model5)</span><br><span class="line">        self.model6 = nn.Sequential(*model6)</span><br><span class="line">        self.model7 = nn.Sequential(*model7)</span><br><span class="line">        self.model8 = nn.Sequential(*model8)</span><br><span class="line"></span><br><span class="line">        self.softmax = nn.Softmax(dim=1)</span><br><span class="line">        # 输出层，将313的输入通道转为2的输出通道，返回ab的通道</span><br><span class="line">        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)</span><br><span class="line">        # 上采样层，线性4倍空间大小上采样</span><br><span class="line">        # （论文原话）分辨率的所有更改都是通过转换块之间的空间下采样或上采样实现的</span><br><span class="line">        self.upsample4 = nn.Upsample(scale_factor=4, mode=&#x27;bilinear&#x27;)</span><br><span class="line"></span><br><span class="line">    # 前向传递搭建网络层，输入input_l（输入的灰度图像L通道）</span><br><span class="line">    def forward(self, input_l):</span><br><span class="line">        # 输入的L通道经过归一化后输入CONV1层</span><br><span class="line">        conv1_2 = self.model1(self.normalize_l(input_l))</span><br><span class="line">        conv2_2 = self.model2(conv1_2)</span><br><span class="line">        conv3_3 = self.model3(conv2_2)</span><br><span class="line">        conv4_3 = self.model4(conv3_3)</span><br><span class="line">        conv5_3 = self.model5(conv4_3)</span><br><span class="line">        conv6_3 = self.model6(conv5_3)</span><br><span class="line">        conv7_3 = self.model7(conv6_3)</span><br><span class="line">        conv8_3 = self.model8(conv7_3)</span><br><span class="line">        # ECCVGenerator的输出结果是第8层CONV的softmax的输出层计算结果</span><br><span class="line">        # 返回的（应该是）ab的通道预测概率</span><br><span class="line">        out_reg = self.model_out(self.softmax(conv8_3))</span><br><span class="line">        # 返回的是ab颜色的值</span><br><span class="line">        return self.unnormalize_ab(self.upsample4(out_reg))</span><br><span class="line"></span><br><span class="line">def eccv16(pretrained=True):</span><br><span class="line">	model = ECCVGenerator()</span><br><span class="line">	if(pretrained):</span><br><span class="line">		import torch.utils.model_zoo as model_zoo</span><br><span class="line">		model.load_state_dict(model_zoo.load_url(&#x27;https://colorizers.s3.us-east-2.amazonaws.com/colorization_release_v2-9b330a0b.pth&#x27;,map_location=&#x27;cpu&#x27;,check_hash=True))</span><br><span class="line">	return model</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line">#siggraphmodel.py：</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from .base_color import *</span><br><span class="line"></span><br><span class="line">class SIGGRAPHGenerator(BaseColor):</span><br><span class="line">    def __init__(self, norm_layer=nn.BatchNorm2d, classes=529):</span><br><span class="line">        super(SIGGRAPHGenerator, self).__init__()</span><br><span class="line"></span><br><span class="line">        # Conv1</span><br><span class="line">        model1=[nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model1+=[nn.ReLU(True),]</span><br><span class="line">        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model1+=[nn.ReLU(True),]</span><br><span class="line">        model1+=[norm_layer(64),]</span><br><span class="line">        # add a subsampling operation</span><br><span class="line"></span><br><span class="line">        # Conv2</span><br><span class="line">        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model2+=[nn.ReLU(True),]</span><br><span class="line">        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model2+=[nn.ReLU(True),]</span><br><span class="line">        model2+=[norm_layer(128),]</span><br><span class="line">        # add a subsampling layer operation</span><br><span class="line"></span><br><span class="line">        # Conv3</span><br><span class="line">        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model3+=[nn.ReLU(True),]</span><br><span class="line">        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model3+=[nn.ReLU(True),]</span><br><span class="line">        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model3+=[nn.ReLU(True),]</span><br><span class="line">        model3+=[norm_layer(256),]</span><br><span class="line">        # add a subsampling layer operation</span><br><span class="line"></span><br><span class="line">        # Conv4</span><br><span class="line">        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model4+=[nn.ReLU(True),]</span><br><span class="line">        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model4+=[nn.ReLU(True),]</span><br><span class="line">        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model4+=[nn.ReLU(True),]</span><br><span class="line">        model4+=[norm_layer(512),]</span><br><span class="line"></span><br><span class="line">        # Conv5</span><br><span class="line">        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model5+=[nn.ReLU(True),]</span><br><span class="line">        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model5+=[nn.ReLU(True),]</span><br><span class="line">        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model5+=[nn.ReLU(True),]</span><br><span class="line">        model5+=[norm_layer(512),]</span><br><span class="line"></span><br><span class="line">        # Conv6</span><br><span class="line">        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model6+=[nn.ReLU(True),]</span><br><span class="line">        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model6+=[nn.ReLU(True),]</span><br><span class="line">        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]</span><br><span class="line">        model6+=[nn.ReLU(True),]</span><br><span class="line">        model6+=[norm_layer(512),]</span><br><span class="line"></span><br><span class="line">        # Conv7</span><br><span class="line">        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model7+=[nn.ReLU(True),]</span><br><span class="line">        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model7+=[nn.ReLU(True),]</span><br><span class="line">        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model7+=[nn.ReLU(True),]</span><br><span class="line">        model7+=[norm_layer(512),]</span><br><span class="line"></span><br><span class="line">        # Conv7</span><br><span class="line">        model8up=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True)]</span><br><span class="line">        model3short8=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line"></span><br><span class="line">        model8=[nn.ReLU(True),]</span><br><span class="line">        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model8+=[nn.ReLU(True),]</span><br><span class="line">        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model8+=[nn.ReLU(True),]</span><br><span class="line">        model8+=[norm_layer(256),]</span><br><span class="line"></span><br><span class="line">        # Conv9</span><br><span class="line">        model9up=[nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=True),]</span><br><span class="line">        model2short9=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        # add the two feature maps above        </span><br><span class="line"></span><br><span class="line">        model9=[nn.ReLU(True),]</span><br><span class="line">        model9+=[nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        model9+=[nn.ReLU(True),]</span><br><span class="line">        model9+=[norm_layer(128),]</span><br><span class="line"></span><br><span class="line">        # Conv10</span><br><span class="line">        model10up=[nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=True),]</span><br><span class="line">        model1short10=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]</span><br><span class="line">        # add the two feature maps above</span><br><span class="line"></span><br><span class="line">        model10=[nn.ReLU(True),]</span><br><span class="line">        model10+=[nn.Conv2d(128, 128, kernel_size=3, dilation=1, stride=1, padding=1, bias=True),]</span><br><span class="line">        model10+=[nn.LeakyReLU(negative_slope=.2),]</span><br><span class="line"></span><br><span class="line">        # classification output</span><br><span class="line">        model_class=[nn.Conv2d(256, classes, kernel_size=1, padding=0, dilation=1, stride=1, bias=True),]</span><br><span class="line"></span><br><span class="line">        # regression output</span><br><span class="line">        model_out=[nn.Conv2d(128, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=True),]</span><br><span class="line">        model_out+=[nn.Tanh()]</span><br><span class="line"></span><br><span class="line">        self.model1 = nn.Sequential(*model1)</span><br><span class="line">        self.model2 = nn.Sequential(*model2)</span><br><span class="line">        self.model3 = nn.Sequential(*model3)</span><br><span class="line">        self.model4 = nn.Sequential(*model4)</span><br><span class="line">        self.model5 = nn.Sequential(*model5)</span><br><span class="line">        self.model6 = nn.Sequential(*model6)</span><br><span class="line">        self.model7 = nn.Sequential(*model7)</span><br><span class="line">        self.model8up = nn.Sequential(*model8up)</span><br><span class="line">        self.model8 = nn.Sequential(*model8)</span><br><span class="line">        self.model9up = nn.Sequential(*model9up)</span><br><span class="line">        self.model9 = nn.Sequential(*model9)</span><br><span class="line">        self.model10up = nn.Sequential(*model10up)</span><br><span class="line">        self.model10 = nn.Sequential(*model10)</span><br><span class="line">        self.model3short8 = nn.Sequential(*model3short8)</span><br><span class="line">        self.model2short9 = nn.Sequential(*model2short9)</span><br><span class="line">        self.model1short10 = nn.Sequential(*model1short10)</span><br><span class="line"></span><br><span class="line">        self.model_class = nn.Sequential(*model_class)</span><br><span class="line">        self.model_out = nn.Sequential(*model_out)</span><br><span class="line"></span><br><span class="line">        self.upsample4 = nn.Sequential(*[nn.Upsample(scale_factor=4, mode=&#x27;bilinear&#x27;),])</span><br><span class="line">        self.softmax = nn.Sequential(*[nn.Softmax(dim=1),])</span><br><span class="line"></span><br><span class="line">    def forward(self, input_A, input_B=None, mask_B=None):</span><br><span class="line">        if(input_B is None):</span><br><span class="line">            input_B = torch.cat((input_A*0, input_A*0), dim=1)</span><br><span class="line">        if(mask_B is None):</span><br><span class="line">            mask_B = input_A*0</span><br><span class="line"></span><br><span class="line">        conv1_2 = self.model1(torch.cat((self.normalize_l(input_A),self.normalize_ab(input_B),mask_B),dim=1))</span><br><span class="line">        conv2_2 = self.model2(conv1_2[:,:,::2,::2])</span><br><span class="line">        conv3_3 = self.model3(conv2_2[:,:,::2,::2])</span><br><span class="line">        conv4_3 = self.model4(conv3_3[:,:,::2,::2])</span><br><span class="line">        conv5_3 = self.model5(conv4_3)</span><br><span class="line">        conv6_3 = self.model6(conv5_3)</span><br><span class="line">        conv7_3 = self.model7(conv6_3)</span><br><span class="line"></span><br><span class="line">        conv8_up = self.model8up(conv7_3) + self.model3short8(conv3_3)</span><br><span class="line">        conv8_3 = self.model8(conv8_up)</span><br><span class="line">        conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2)</span><br><span class="line">        conv9_3 = self.model9(conv9_up)</span><br><span class="line">        conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2)</span><br><span class="line">        conv10_2 = self.model10(conv10_up)</span><br><span class="line">        out_reg = self.model_out(conv10_2)</span><br><span class="line"></span><br><span class="line">        conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2)</span><br><span class="line">        conv9_3 = self.model9(conv9_up)</span><br><span class="line">        conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2)</span><br><span class="line">        conv10_2 = self.model10(conv10_up)</span><br><span class="line">        out_reg = self.model_out(conv10_2)</span><br><span class="line"></span><br><span class="line">        return self.unnormalize_ab(out_reg)</span><br><span class="line"></span><br><span class="line">def siggraph17(pretrained=True):</span><br><span class="line">    model = SIGGRAPHGenerator()</span><br><span class="line">  #下载模型</span><br><span class="line">    if(pretrained):</span><br><span class="line">        import torch.utils.model_zoo as model_zoo</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(&#x27;https://colorizers.s3.us-east-2.amazonaws.com/siggraph17-df00044c.pth&#x27;,map_location=&#x27;cpu&#x27;,check_hash=True))</span><br><span class="line">    return model</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">#util.py：</span><br><span class="line">#处理图像的类PIL，数据处理的numpy，PIL和Pillow只提供最基础的数字图像处理，功能有限。</span><br><span class="line">#opencv实际上是一个c++库，只是提供了python接口，更新速度非常慢。</span><br><span class="line">#scikit-image是基于scipy的一款图像处理包，它将图片作为numpy数组进行处理，正好与matlab一样，因此，我们最终选择scikit-image进行数字图像处理。</span><br><span class="line">#进行图像规格的统一及通道的转换</span><br><span class="line">from PIL import Image</span><br><span class="line">import numpy as np</span><br><span class="line">from skimage import color</span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">from IPython import embed</span><br><span class="line">#载入图片</span><br><span class="line">def load_img(img_path):</span><br><span class="line">	out_np = np.asarray(Image.open(img_path))</span><br><span class="line">	if(out_np.ndim==2):</span><br><span class="line">		out_np = np.tile(out_np[:,:,None],3)</span><br><span class="line">	return out_np</span><br><span class="line">#先把图片尺寸进行修改，转换为256*256</span><br><span class="line">#当数据源是ndarray时，array仍然会copy出一个副本，占用新的内存，但asarray不会。resample重采样</span><br><span class="line">def resize_img(img, HW=(256,256), resample=3):</span><br><span class="line">	return np.asarray(Image.fromarray(img).resize((HW[1],HW[0]), resample=resample))</span><br><span class="line">#图片规格定为HW,尺寸为256*256，将数据转换成Tensor，便于模型使用</span><br><span class="line">def preprocess_img(img_rgb_orig, HW=(256,256), resample=3):</span><br><span class="line">	# return original size L and resized L as torch Tensors</span><br><span class="line">	img_rgb_rs = resize_img(img_rgb_orig, HW=HW, resample=resample)</span><br><span class="line">	#将rgb图片转换为lab形式。用于之后预测ab通道</span><br><span class="line">	img_lab_orig = color.rgb2lab(img_rgb_orig)</span><br><span class="line">	img_lab_rs = color.rgb2lab(img_rgb_rs)</span><br><span class="line"></span><br><span class="line">	img_l_orig = img_lab_orig[:,:,0]</span><br><span class="line">	img_l_rs = img_lab_rs[:,:,0]</span><br><span class="line"></span><br><span class="line">	tens_orig_l = torch.Tensor(img_l_orig)[None,None,:,:]</span><br><span class="line">	tens_rs_l = torch.Tensor(img_l_rs)[None,None,:,:]</span><br><span class="line"></span><br><span class="line">	return (tens_orig_l, tens_rs_l)</span><br><span class="line"></span><br><span class="line">def postprocess_tens(tens_orig_l, out_ab, mode=&#x27;bilinear&#x27;):</span><br><span class="line">	# tens_orig_l 	1 x 1 x H_orig x W_orig</span><br><span class="line">	# out_ab 		1 x 2 x H x W</span><br><span class="line">	#取彩色图片的长、宽。</span><br><span class="line">	HW_orig = tens_orig_l.shape[2:]</span><br><span class="line">	HW = out_ab.shape[2:]</span><br><span class="line"></span><br><span class="line">	# call resize function if needed</span><br><span class="line">	#上采样算法: nearest, linear, bilinear, trilinear, area.默认为</span><br><span class="line">	#nearest.如果采样后图像的长宽发生变化，我们将图像填充成采样后的图像尺寸</span><br><span class="line">	if(HW_orig[0]!=HW[0] or HW_orig[1]!=HW[1]):</span><br><span class="line">		out_ab_orig = F.interpolate(out_ab, size=HW_orig, mode=&#x27;bilinear&#x27;)</span><br><span class="line">	else:</span><br><span class="line">		out_ab_orig = out_ab</span><br><span class="line"># torch.cat的功能是将多个tensor类型矩阵的连接</span><br><span class="line">	out_lab_orig = torch.cat((tens_orig_l, out_ab_orig), dim=1)</span><br><span class="line">	#a.data.cpu().numpy()把tensor转换成numpy的格式</span><br><span class="line">	return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">#demo_release.py：</span><br><span class="line"></span><br><span class="line">import argparse</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">from colorizers import *</span><br><span class="line">#导入图像</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&#x27;-i&#x27;,&#x27;--img_path&#x27;, type=str, default=&#x27;imgs/ansel_adams2.jpg&#x27;)</span><br><span class="line">parser.add_argument(&#x27;--use_gpu&#x27;, action=&#x27;store_true&#x27;, help=&#x27;whether to use GPU&#x27;)</span><br><span class="line">parser.add_argument(&#x27;-o&#x27;,&#x27;--save_prefix&#x27;, type=str, default=&#x27;saved&#x27;, help=&#x27;will save into this file with &#123;eccv16.png, siggraph17.png&#125; suffixes&#x27;)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line"># 载入着色，预训练的模型通过将其权重和偏差矩阵传递给新模型，eval() 函数用来执行一个字符串表达式,并返回表达式的值。</span><br><span class="line">colorizer_eccv16 = eccv16(pretrained=True).eval()</span><br><span class="line">colorizer_siggraph17 = siggraph17(pretrained=True).eval()</span><br><span class="line">#如果使用gpu加载，用cuda运算方法，提高运算效率</span><br><span class="line">if(opt.use_gpu):</span><br><span class="line">	colorizer_eccv16.cuda()</span><br><span class="line">	colorizer_siggraph17.cuda()</span><br><span class="line"></span><br><span class="line"># 默认将要被处理的图像尺寸为 256x256</span><br><span class="line"># grab L channel in both original ( &quot;orig&quot;) and resized (&quot;rs&quot;) resolutions</span><br><span class="line"># 在原始图像和调整大小和调整尺寸后的图像分别抓取L通道</span><br><span class="line"></span><br><span class="line">img = load_img(opt.img_path)</span><br><span class="line">(tens_l_orig, tens_l_rs) = preprocess_img(img, HW=(256,256))</span><br><span class="line">if(opt.use_gpu):</span><br><span class="line">	tens_l_rs = tens_l_rs.cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 着色器输出256×256 ab映射</span><br><span class="line"></span><br><span class="line"># #调整大小并连接到原来的L通道</span><br><span class="line">img_bw = postprocess_tens(tens_l_orig, torch.cat((0*tens_l_orig,0*tens_l_orig),dim=1))</span><br><span class="line">out_img_eccv16 = postprocess_tens(tens_l_orig, colorizer_eccv16(tens_l_rs).cpu())</span><br><span class="line">out_img_siggraph17 = postprocess_tens(tens_l_orig, colorizer_siggraph17(tens_l_rs).cpu())</span><br><span class="line">#保存输出图像</span><br><span class="line">plt.imsave(&#x27;%s_eccv16.png&#x27;%opt.save_prefix, out_img_eccv16)</span><br><span class="line">plt.imsave(&#x27;%s_siggraph17.png&#x27;%opt.save_prefix, out_img_siggraph17)</span><br><span class="line">#绘图，创建自定义图像，绘制子图</span><br><span class="line">plt.figure(figsize=(12,8))</span><br><span class="line">plt.subplot(2,2,1)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.title(&#x27;Original&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,2)</span><br><span class="line">plt.imshow(img_bw)</span><br><span class="line">plt.title(&#x27;Input&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,3)</span><br><span class="line">plt.imshow(out_img_eccv16)</span><br><span class="line">plt.title(&#x27;Output (ECCV 16)&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,4)</span><br><span class="line">plt.imshow(out_img_siggraph17)</span><br><span class="line">plt.title(&#x27;Output (SIGGRAPH 17)&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>图例：</strong></p>
<p><img src="E:\MyBlog\public\img\图例.png" alt="image-20220522224801712"></p>
<h2 id="导入已训练的模型"><a href="#导入已训练的模型" class="headerlink" title="导入已训练的模型"></a><strong>导入已训练的模型</strong></h2><p><strong>开始着色!</strong> 在Python中加载模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo_release.py -i imgs/ansel_adams3.jpg</span><br></pre></td></tr></table></figure>

<p>以下加载预训练的着色器。有关如何运行模型的一些详细信息，请参见演示 <a target="_blank" rel="noopener" href="https://github.com/richzhang/colorization/blob/master/demo_release.py">demo_release.py</a>，有一些预处理和后处理步骤：转换到实验室空间，调整大小到256x256，着色，并连接到原始的完全分辨率，并转换为RGB。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">#处理图像的类PIL，数据处理的numpy，PIL和Pillow只提供最基础的数字图像处理，功能有限。</span><br><span class="line">#opencv实际上是一个c++库，只是提供了python接口，更新速度非常慢。</span><br><span class="line">#scikit-image是基于scipy的一款图像处理包，它将图片作为numpy数组进行处理，正好与matlab一样，因此，我们最终选择scikit-image进行数字图像处理。</span><br><span class="line">#进行图像规格的统一及通道的转换</span><br><span class="line">from PIL import Image</span><br><span class="line">import numpy as np</span><br><span class="line">from skimage import color</span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">from IPython import embed</span><br><span class="line">#载入图片</span><br><span class="line">def load_img(img_path):</span><br><span class="line">	out_np = np.asarray(Image.open(img_path))</span><br><span class="line">	if(out_np.ndim==2):</span><br><span class="line">		out_np = np.tile(out_np[:,:,None],3)</span><br><span class="line">	return out_np</span><br><span class="line">#先把图片尺寸进行修改，转换为256*256</span><br><span class="line">#当数据源是ndarray时，array仍然会copy出一个副本，占用新的内存，但asarray不会。resample重采样</span><br><span class="line">def resize_img(img, HW=(256,256), resample=3):</span><br><span class="line">	return np.asarray(Image.fromarray(img).resize((HW[1],HW[0]), resample=resample))</span><br><span class="line">#图片规格定为HW,尺寸为256*256，将数据转换成Tensor，便于模型使用</span><br><span class="line">def preprocess_img(img_rgb_orig, HW=(256,256), resample=3):</span><br><span class="line">	# return original size L and resized L as torch Tensors</span><br><span class="line">	img_rgb_rs = resize_img(img_rgb_orig, HW=HW, resample=resample)</span><br><span class="line">	#将rgb图片转换为lab形式。用于之后预测ab通道</span><br><span class="line">	img_lab_orig = color.rgb2lab(img_rgb_orig)</span><br><span class="line">	img_lab_rs = color.rgb2lab(img_rgb_rs)</span><br><span class="line"></span><br><span class="line">	img_l_orig = img_lab_orig[:,:,0]</span><br><span class="line">	img_l_rs = img_lab_rs[:,:,0]</span><br><span class="line"></span><br><span class="line">	tens_orig_l = torch.Tensor(img_l_orig)[None,None,:,:]</span><br><span class="line">	tens_rs_l = torch.Tensor(img_l_rs)[None,None,:,:]</span><br><span class="line"></span><br><span class="line">	return (tens_orig_l, tens_rs_l)</span><br><span class="line"></span><br><span class="line">def postprocess_tens(tens_orig_l, out_ab, mode=&#x27;bilinear&#x27;):</span><br><span class="line">	# tens_orig_l 	1 x 1 x H_orig x W_orig</span><br><span class="line">	# out_ab 		1 x 2 x H x W</span><br><span class="line">	#取彩色图片的长、宽。</span><br><span class="line">	HW_orig = tens_orig_l.shape[2:]</span><br><span class="line">	HW = out_ab.shape[2:]</span><br><span class="line"></span><br><span class="line">	# call resize function if needed</span><br><span class="line">	#上采样算法: nearest, linear, bilinear, trilinear, area.默认为</span><br><span class="line">	#nearest.如果采样后图像的长宽发生变化，我们将图像填充成采样后的图像尺寸</span><br><span class="line">	if(HW_orig[0]!=HW[0] or HW_orig[1]!=HW[1]):</span><br><span class="line">		out_ab_orig = F.interpolate(out_ab, size=HW_orig, mode=&#x27;bilinear&#x27;)</span><br><span class="line">	else:</span><br><span class="line">		out_ab_orig = out_ab</span><br><span class="line"># torch.cat的功能是将多个tensor类型矩阵的连接</span><br><span class="line">	out_lab_orig = torch.cat((tens_orig_l, out_ab_orig), dim=1)</span><br><span class="line">	#a.data.cpu().numpy()把tensor转换成numpy的格式</span><br><span class="line">	return color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))</span><br><span class="line"></span><br><span class="line">colorizer_eccv16 = colorizers.eccv16().eval()</span><br><span class="line">colorizer_siggraph17 = colorizers.siggraph17().eval()</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">from colorizers import *</span><br><span class="line">#导入图像</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&#x27;-i&#x27;,&#x27;--img_path&#x27;, type=str, default=&#x27;imgs/ansel_adams2.jpg&#x27;)</span><br><span class="line">parser.add_argument(&#x27;--use_gpu&#x27;, action=&#x27;store_true&#x27;, help=&#x27;whether to use GPU&#x27;)</span><br><span class="line">parser.add_argument(&#x27;-o&#x27;,&#x27;--save_prefix&#x27;, type=str, default=&#x27;saved&#x27;, help=&#x27;will save into this file with &#123;eccv16.png, siggraph17.png&#125; suffixes&#x27;)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line"># 载入着色，预训练的模型通过将其权重和偏差矩阵传递给新模型，eval() 函数用来执行一个字符串表达式,并返回表达式的值。</span><br><span class="line">colorizer_eccv16 = eccv16(pretrained=True).eval()</span><br><span class="line">colorizer_siggraph17 = siggraph17(pretrained=True).eval()</span><br><span class="line">#如果使用gpu加载，用cuda运算方法，提高运算效率</span><br><span class="line">if(opt.use_gpu):</span><br><span class="line">   colorizer_eccv16.cuda()</span><br><span class="line">   colorizer_siggraph17.cuda()</span><br><span class="line"></span><br><span class="line"># 默认将要被处理的图像尺寸为 256x256</span><br><span class="line"># grab L channel in both original ( &quot;orig&quot;) and resized (&quot;rs&quot;) resolutions</span><br><span class="line"># 在原始图像和调整大小和调整尺寸后的图像分别抓取L通道</span><br><span class="line"></span><br><span class="line">img = load_img(opt.img_path)</span><br><span class="line">(tens_l_orig, tens_l_rs) = preprocess_img(img, HW=(256,256))</span><br><span class="line">if(opt.use_gpu):</span><br><span class="line">   tens_l_rs = tens_l_rs.cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 着色器输出256×256 ab映射</span><br><span class="line"></span><br><span class="line"># #调整大小并连接到原来的L通道</span><br><span class="line">img_bw = postprocess_tens(tens_l_orig, torch.cat((0*tens_l_orig,0*tens_l_orig),dim=1))</span><br><span class="line">out_img_eccv16 = postprocess_tens(tens_l_orig, colorizer_eccv16(tens_l_rs).cpu())</span><br><span class="line">out_img_siggraph17 = postprocess_tens(tens_l_orig, colorizer_siggraph17(tens_l_rs).cpu())</span><br><span class="line">#保存输出图像</span><br><span class="line">plt.imsave(&#x27;%s_eccv16.png&#x27;%opt.save_prefix, out_img_eccv16)</span><br><span class="line">plt.imsave(&#x27;%s_siggraph17.png&#x27;%opt.save_prefix, out_img_siggraph17)</span><br><span class="line">#绘图，创建自定义图像，绘制子图</span><br><span class="line">plt.figure(figsize=(12,8))</span><br><span class="line">plt.subplot(2,2,1)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.title(&#x27;Original&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,2)</span><br><span class="line">plt.imshow(img_bw)</span><br><span class="line">plt.title(&#x27;Input&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,3)</span><br><span class="line">plt.imshow(out_img_eccv16)</span><br><span class="line">plt.title(&#x27;Output (ECCV 16)&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,4)</span><br><span class="line">plt.imshow(out_img_siggraph17)</span><br><span class="line">plt.title(&#x27;Output (SIGGRAPH 17)&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>



</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Exia</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/posts/1a3.html">http://example.com/posts/1a3.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Exiaの格纳库</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></div><div class="post_share"><div class="social-share" data-image="https://ftp.bmp.ovh/imgs/2021/01/3d619086ccfbc6a9.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/c83c.html"><img class="prev-cover" src="https://s3.bmp.ovh/imgs/2023/01/13/6bbed0cb01ec1f40.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Java面经刷题_Day1</div></div></a></div><div class="next-post pull-right"><a href="/posts/5e8c.html"><img class="next-cover" src="https://s3.bmp.ovh/imgs/2021/11/deeef640fbc8c012.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">人工智能课堂问题 其一</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/5e8c.html" title="人工智能课堂问题 其一"><img class="cover" src="https://s3.bmp.ovh/imgs/2021/11/deeef640fbc8c012.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-19</div><div class="title">人工智能课堂问题 其一</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Exia</div><div class="author-info__description">希望好心情每天都照常营业</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/jing-mo"><i class="fab fa-github"></i><span>关注一下哟</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://space.bilibili.com/3371931" target="_blank" title="B站"><i class="iconfont icon-bilibili1"></i></a><a class="social-icon" href="https://github.com/jing-mo" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/1700831567@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">星光不问赶路人 时光不负追梦人<img src="https://z3.ax1x.com/2021/08/22/hSD5x1.gif"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9B%BE%E5%83%8F%E7%9D%80%E8%89%B2%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">基于深度学习的图像着色系统项目介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%93%E7%9A%84%E6%94%AF%E6%8C%81"><span class="toc-number">1.1.</span> <span class="toc-text">库的支持</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#torch"><span class="toc-number">1.1.1.</span> <span class="toc-text">torch</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-torch-nn%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%8A%9F%E8%83%BD"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">1.1 torch.nn简介与功能</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E8%8E%B7%E5%8F%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">2.1 获取神经网络的模型参数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E9%87%8D%E8%A6%81%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%E4%B8%8E%E5%BD%92%E7%BA%B3"><span class="toc-number">1.1.1.2.1.</span> <span class="toc-text">项目中的重要方法总结与归纳:</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E4%B8%BB%E8%A6%81%E7%9A%84%E5%AE%B9%E5%99%A8"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">2.2 主要的容器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E7%BA%BF%E6%80%A7%E5%B1%82"><span class="toc-number">1.1.1.4.</span> <span class="toc-text">2.3 线性层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.1.5.</span> <span class="toc-text">2.4 非线性激活函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.1.6.</span> <span class="toc-text">2.5 非线性激活函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6-%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86"><span class="toc-number">1.1.1.7.</span> <span class="toc-text">2.6 归一化处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-7-%E5%90%84%E7%A7%8D%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.1.8.</span> <span class="toc-text">2.7 各种损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-8-CNN%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">1.1.1.9.</span> <span class="toc-text">2.8 CNN卷积层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-9-pooling%E5%B1%82"><span class="toc-number">1.1.1.10.</span> <span class="toc-text">2.9 pooling层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-10-%E5%A1%AB%E5%85%85%E5%B1%82"><span class="toc-number">1.1.1.11.</span> <span class="toc-text">2.10 填充层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-11-RNN%E7%BD%91%E7%BB%9C%E5%B1%82"><span class="toc-number">1.1.1.12.</span> <span class="toc-text">2.11 RNN网络层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-12-Dropout%E5%B1%82%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.1.13.</span> <span class="toc-text">2.12 Dropout层定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-13-Sparse-layers"><span class="toc-number">1.1.1.14.</span> <span class="toc-text">2.13 Sparse layers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-14-%E8%B7%9D%E7%A6%BB%E5%8A%9F%E8%83%BD"><span class="toc-number">1.1.1.15.</span> <span class="toc-text">2.14 距离功能</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-15-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B1%82"><span class="toc-number">1.1.1.16.</span> <span class="toc-text">2.15 可视化层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-16-%E5%B9%B6%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%B1%82"><span class="toc-number">1.1.1.17.</span> <span class="toc-text">2.16 并行数据层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-17-%E5%90%84%E7%A7%8D%E5%B7%A5%E5%85%B7"><span class="toc-number">1.1.1.18.</span> <span class="toc-text">2.17 各种工具</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-18-tensor%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.1.19.</span> <span class="toc-text">2.18  tensor简介</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Ski-image"><span class="toc-number">1.1.2.</span> <span class="toc-text">Ski-image</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#skimage%E7%9A%84%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">skimage的简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%AD%90%E6%A8%A1%E5%9D%97%E5%88%97%E8%A1%A8%E5%A6%82%E4%B8%8B"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">主要子模块列表如下</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#numpy"><span class="toc-number">1.1.3.</span> <span class="toc-text">numpy</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#NumPy-%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">NumPy- 简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NumPy-%E6%93%8D%E4%BD%9C"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">NumPy 操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NumPy-Ndarray-%E5%AF%B9%E8%B1%A1"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">NumPy - Ndarray 对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NumPy-asarray%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.3.4.</span> <span class="toc-text">NumPy-asarray函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#np-tile"><span class="toc-number">1.1.3.5.</span> <span class="toc-text">np.tile</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AF%B9%E8%B1%A1-dtype"><span class="toc-number">1.1.3.6.</span> <span class="toc-text">数据类型对象 (dtype)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#matplotlib"><span class="toc-number">1.1.4.</span> <span class="toc-text">matplotlib</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#pyplot%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">pyplot简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%84%E5%AE%9Aplot%E7%9A%84%E5%BD%A2%E5%BC%8F"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">规定plot的形式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%85%B3%E9%94%AE%E5%AD%97plotting"><span class="toc-number">1.1.4.3.</span> <span class="toc-text">使用关键字plotting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E7%BA%BF%E5%B1%9E%E6%80%A7"><span class="toc-number">1.1.4.4.</span> <span class="toc-text">控制线属性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AAfigure%E5%92%8Caxes"><span class="toc-number">1.1.4.5.</span> <span class="toc-text">使用多个figure和axes</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8text"><span class="toc-number">1.1.4.6.</span> <span class="toc-text">使用text</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E9%87%8C%E7%94%A8%E6%95%B0%E5%AD%A6%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="toc-number">1.1.4.7.</span> <span class="toc-text">文本里用数学表达式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%A8%E9%87%8A%E6%96%87%E6%9C%AC"><span class="toc-number">1.1.4.8.</span> <span class="toc-text">注释文本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%95%B0%E5%92%8C%E5%85%B6%E4%BB%96%E9%9D%9E%E7%BA%BF%E6%80%A7%E7%9A%84axes"><span class="toc-number">1.1.4.9.</span> <span class="toc-text">对数和其他非线性的axes</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pillow%EF%BC%88PIL%EF%BC%89"><span class="toc-number">1.1.5.</span> <span class="toc-text">pillow（PIL）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E4%BD%BF%E7%94%A8-Image-open-%E5%88%9B%E5%BB%BA%E5%9B%BE%E5%83%8F%E5%AE%9E%E4%BE%8B"><span class="toc-number">1.1.5.1.</span> <span class="toc-text">一、使用 Image.open() 创建图像实例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E9%80%9A%E8%BF%87%E6%96%87%E4%BB%B6%E5%88%9B%E5%BB%BA-Image-%E5%AF%B9%E8%B1%A1"><span class="toc-number">1.1.5.2.</span> <span class="toc-text">1. 通过文件创建 Image 对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%BB%8E%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E4%B8%AD%E8%AF%BB%E5%8F%96"><span class="toc-number">1.1.5.3.</span> <span class="toc-text">2. 从打开文件中读取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E4%BB%8E-string-%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%B5%81%E4%B8%AD%E8%AF%BB%E5%8F%96"><span class="toc-number">1.1.5.4.</span> <span class="toc-text">3. 从 string 二进制流中读取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E4%BB%8Etar%E6%96%87%E4%BB%B6%E4%B8%AD%E8%AF%BB%E5%8F%96"><span class="toc-number">1.1.5.5.</span> <span class="toc-text">4. 从tar文件中读取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E8%AF%BB%E5%86%99%E5%9B%BE%E5%83%8F"><span class="toc-number">1.1.5.6.</span> <span class="toc-text">二、读写图像</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%9B%BE%E5%83%8F"><span class="toc-number">1.1.5.6.1.</span> <span class="toc-text">1. 格式转换并保存图像</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%88%9B%E5%BB%BA%E7%BC%A9%E7%95%A5%E5%9B%BE"><span class="toc-number">1.1.5.6.2.</span> <span class="toc-text">2. 创建缩略图</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%89%AA%E8%B4%B4%EF%BC%8C%E7%B2%98%E8%B4%B4%E3%80%81%E5%90%88%E5%B9%B6%E5%9B%BE%E5%83%8F"><span class="toc-number">1.1.5.7.</span> <span class="toc-text">三、剪贴，粘贴、合并图像</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E4%BB%8E%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%88%B6%E5%AD%90%E7%9F%A9%E5%BD%A2"><span class="toc-number">1.1.5.7.1.</span> <span class="toc-text">1. 从图像复制子矩形</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%A4%84%E7%90%86%E5%AD%90%E7%9F%A9%E5%BD%A2%E5%B9%B6%E5%B0%86%E5%85%B6%E7%B2%98%E8%B4%B4%E5%9B%9E%E6%9D%A5"><span class="toc-number">1.1.5.7.2.</span> <span class="toc-text">2. 处理子矩形并将其粘贴回来</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%88%86%E7%A6%BB%E5%92%8C%E5%90%88%E5%B9%B6%E9%80%9A%E9%81%93"><span class="toc-number">1.1.5.7.3.</span> <span class="toc-text">3. 分离和合并通道</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B-%E5%87%A0%E4%BD%95%E5%8F%98%E6%8D%A2"><span class="toc-number">1.1.5.8.</span> <span class="toc-text">四. 几何变换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%94-%E9%A2%9C%E8%89%B2%E5%8F%98%E6%8D%A2"><span class="toc-number">1.1.5.9.</span> <span class="toc-text">五. 颜色变换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%AD-%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA"><span class="toc-number">1.1.5.10.</span> <span class="toc-text">六. 图像增强</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-Filters-%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="toc-number">1.1.5.10.1.</span> <span class="toc-text">1. Filters 过滤器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%83%8F%E7%B4%A0%E7%82%B9%E5%A4%84%E7%90%86"><span class="toc-number">1.1.5.10.2.</span> <span class="toc-text">2. 像素点处理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%A4%84%E7%90%86%E5%8D%95%E7%8B%AC%E9%80%9A%E9%81%93"><span class="toc-number">1.1.5.10.3.</span> <span class="toc-text">3. 处理单独通道</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E9%AB%98%E7%BA%A7%E5%A2%9E%E5%BC%BA"><span class="toc-number">1.1.5.11.</span> <span class="toc-text">七、高级增强</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%AB%E3%80%81-%E5%8A%A8%E6%80%81%E5%9B%BE%E5%83%8F"><span class="toc-number">1.1.5.12.</span> <span class="toc-text">八、 动态图像</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B9%9D%E3%80%81Postscript-%E6%89%93%E5%8D%B0"><span class="toc-number">1.1.5.13.</span> <span class="toc-text">九、Postscript 打印</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%81%E3%80%81%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD%E5%99%A8-draft"><span class="toc-number">1.1.5.14.</span> <span class="toc-text">十、配置加载器 draft</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#argparse"><span class="toc-number">1.1.6.</span> <span class="toc-text">argparse</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E7%9D%80%E8%89%B2%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%90%86%E8%AE%BA%E6%94%AF%E6%8C%81%E2%80%94%E2%80%94%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E3%80%81%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E7%BB%93%E5%90%88"><span class="toc-number">1.2.</span> <span class="toc-text">图像着色系统的理论支持——计算机图形学、图像处理技术与人工智能的结合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86"><span class="toc-number">1.2.1.</span> <span class="toc-text">图像归一化处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.2.2.</span> <span class="toc-text">卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">多卷积核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">卷积的计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E9%80%9A%E9%81%93%E5%8D%95%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">单通道单卷积核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E9%80%9A%E9%81%93%E5%A4%9A%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">单通道多卷积核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E9%80%9A%E9%81%93%E5%8D%95%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">1.2.2.5.</span> <span class="toc-text">多通道单卷积核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E9%80%9A%E9%81%93%E5%A4%9A%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">1.2.2.6.</span> <span class="toc-text">多通道多卷积核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.2.2.7.</span> <span class="toc-text">为什么需要深度卷积</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%86%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.2.3.</span> <span class="toc-text">逆卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%EF%BC%88Dilated-Convolution%EF%BC%89"><span class="toc-number">1.2.4.</span> <span class="toc-text">空洞卷积（Dilated Convolution）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RGB%E4%B8%8ELAB%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.2.5.</span> <span class="toc-text">RGB与LAB颜色空间的转换</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RGB"><span class="toc-number">1.2.5.1.</span> <span class="toc-text">RGB</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LAB"><span class="toc-number">1.2.5.2.</span> <span class="toc-text">LAB</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pre-trained%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.2.6.</span> <span class="toc-text">pre-trained模型的使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-number">1.2.7.</span> <span class="toc-text">网络训练的流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%A0%E5%8C%96"><span class="toc-number">1.2.8.</span> <span class="toc-text">池化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.9.</span> <span class="toc-text">自监督介绍</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">项目结构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E6%80%9D%E8%B7%AF"><span class="toc-number">1.3.0.1.</span> <span class="toc-text">总体思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%8D%E6%9C%9F%E4%BC%98%E5%8C%96"><span class="toc-number">1.3.0.2.</span> <span class="toc-text">前期优化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%8E%E7%BB%AD%E5%A4%84%E7%90%86"><span class="toc-number">1.3.0.3.</span> <span class="toc-text">后续处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.3.0.4.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA"><span class="toc-number">1.3.0.5.</span> <span class="toc-text">模型构建</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">1.3.0.6.</span> <span class="toc-text">创新点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%B4"><span class="toc-number">1.4.</span> <span class="toc-text">代码解说</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%B7%B2%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.5.</span> <span class="toc-text">导入已训练的模型</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/c83c.html" title="Java面经刷题_Day1"><img src="https://s3.bmp.ovh/imgs/2023/01/13/6bbed0cb01ec1f40.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java面经刷题_Day1"/></a><div class="content"><a class="title" href="/posts/c83c.html" title="Java面经刷题_Day1">Java面经刷题_Day1</a><time datetime="2023-01-12T16:00:00.000Z" title="发表于 2023-01-13 00:00:00">2023-01-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/1a3.html" title="基于深度学习的图像着色系统项目介绍"><img src="https://ftp.bmp.ovh/imgs/2021/01/3d619086ccfbc6a9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于深度学习的图像着色系统项目介绍"/></a><div class="content"><a class="title" href="/posts/1a3.html" title="基于深度学习的图像着色系统项目介绍">基于深度学习的图像着色系统项目介绍</a><time datetime="2022-05-22T14:49:23.344Z" title="发表于 2022-05-22 22:49:23">2022-05-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/5e8c.html" title="人工智能课堂问题 其一"><img src="https://s3.bmp.ovh/imgs/2021/11/deeef640fbc8c012.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="人工智能课堂问题 其一"/></a><div class="content"><a class="title" href="/posts/5e8c.html" title="人工智能课堂问题 其一">人工智能课堂问题 其一</a><time datetime="2022-04-19T06:44:16.020Z" title="发表于 2022-04-19 14:44:16">2022-04-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/195f.html" title="蓝桥杯笔记2"><img src="https://s1.ax1x.com/2022/04/08/L9uLCR.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="蓝桥杯笔记2"/></a><div class="content"><a class="title" href="/posts/195f.html" title="蓝桥杯笔记2">蓝桥杯笔记2</a><time datetime="2022-04-08T07:28:46.290Z" title="发表于 2022-04-08 15:28:46">2022-04-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/5705.html" title="OpenGL的配置"><img src="https://s3.bmp.ovh/imgs/2022/03/7efa36e84033c7b0.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OpenGL的配置"/></a><div class="content"><a class="title" href="/posts/5705.html" title="OpenGL的配置">OpenGL的配置</a><time datetime="2022-03-26T07:52:32.707Z" title="发表于 2022-03-26 15:52:32">2022-03-26</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 <i style="color:#FF6A6A;animation: announ_animation 0.8s linear infinite;" class="fa fa-heartbeat"></i> Exia</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    window.valine = new Valine({
      el: '#vcomment',
      appId: 'frzIuNckJMGfv4YNIS9s68it-gzGzoHsz',
      appKey: 'i9ijajJuDbP530q82wsHwrya',
      placeholder: '自古评论出人才',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: true,
      serverURLs: '',
      emojiCDN: 'https://cdn.jsdelivr.net/gh/GamerNoTitle/ValineCDN@master/# emoji CDN',
      emojiMaps: {"bilibilitv2":"bilibilitv/[tv_doge].png","bilibilitv3":"bilibilitv/[tv_亲亲].png","bilibilitv4":"bilibilitv/[tv_偷笑].png","bilibilitv5":"bilibilitv/[tv_再见].png","bilibilitv6":"bilibilitv/[tv_冷漠].png","bilibilitv7":"bilibilitv/[tv_发怒].png","bilibilitv8":"bilibilitv/[tv_发财].png","bilibilitv9":"bilibilitv/[tv_可爱].png","bilibilitv10":"bilibilitv/[tv_吐血].png","bilibilitv11":"bilibilitv/[tv_呆].png","bilibilitv12":"bilibilitv/[tv_呕吐].png","bilibilitv13":"bilibilitv/[tv_困].png","bilibilitv14":"bilibilitv/[tv_坏笑].png","bilibilitv15":"bilibilitv/[tv_大佬].png","bilibilitv16":"bilibilitv/[tv_大哭].png","bilibilitv17":"bilibilitv/[tv_委屈].png","bilibilitv18":"bilibilitv/[tv_害羞].png","bilibilitv19":"bilibilitv/[tv_尴尬].png","bilibilitv20":"bilibilitv/[tv_微笑].png","bilibilitv21":"bilibilitv/[tv_思考].png","bilibilitv22":"bilibilitv/[tv_惊吓].png","bilibilitv23":"bilibilitv/[tv_打脸].png","bilibilitv24":"bilibilitv/[tv_抓狂].png","bilibilitv25":"bilibilitv/[tv_抠鼻].png","bilibilitv26":"bilibilitv/[tv_斜眼笑].png","bilibilitv27":"bilibilitv/[tv_无奈].png","bilibilitv28":"bilibilitv/[tv_晕].png","bilibilitv29":"bilibilitv/[tv_流汗].png","bilibilitv30":"bilibilitv/[tv_流泪].png","bilibilitv31":"bilibilitv/[tv_流鼻血].png","bilibilitv32":"bilibilitv/[tv_点赞].png","bilibilitv33":"bilibilitv/[tv_生气].png","bilibilitv34":"bilibilitv/[tv_生病].png","bilibilitv35":"bilibilitv/[tv_疑问].png","bilibilitv36":"bilibilitv/[tv_白眼].png","bilibilitv37":"bilibilitv/[tv_皱眉].png","bilibilitv38":"bilibilitv/[tv_目瞪口呆].png","bilibilitv39":"bilibilitv/[tv_睡着].png","bilibilitv40":"bilibilitv/[tv_笑哭].png","bilibilitv41":"bilibilitv/[tv_腼腆].png","bilibilitv42":"bilibilitv/[tv_色].png","bilibilitv43":"bilibilitv/[tv_调侃].png","bilibilitv44":"bilibilitv/[tv_调皮].png","bilibilitv45":"bilibilitv/[tv_鄙视].png","bilibilitv46":"bilibilitv/[tv_闭嘴].png","bilibilitv47":"bilibilitv/[tv_难过].png","bilibilitv48":"bilibilitv/[tv_馋].png","bilibilitv49":"bilibilitv/[tv_鬼脸].png","bilibilitv50":"bilibilitv/[tv_黑人问号].png","bilibilitv51":"bilibilitv/[tv_鼓掌].png","QQ1":"QQ/aini.gif","QQ2":"QQ/aixin.gif","QQ3":"QQ/aoman.gif","QQ4":"QQ/baiyan.gif","QQ5":"QQ/bangbangtang.gif","QQ6":"QQ/baojin.gif","QQ7":"QQ/baoquan.gif","QQ8":"QQ/bishi.gif","QQ9":"QQ/bizui.gif","QQ11":"QQ/cahan.gif","QQ12":"QQ/caidao.gif","QQ13":"QQ/chi.gif","QQ14":"QQ/ciya.gif","QQ15":"QQ/dabing.gif","QQ16":"QQ/daku.gif","QQ17":"QQ/dan.gif","QQ18":"QQ/deyi.gif","QQ19":"QQ/doge.gif","QQ20":"QQ/fadai.gif","QQ21":"QQ/fanu.gif","QQ22":"QQ/fendou.gif","QQ23":"QQ/ganga.gif","QQ24":"QQ/gouyin.gif","QQ25":"QQ/guzhang.gif","QQ26":"QQ/haixiu.gif","QQ27":"QQ/hanxiao.gif","QQ28":"QQ/haobang.gif","QQ29":"QQ/haqian.gif","QQ30":"QQ/hecai.gif","QQ31":"QQ/hexie.gif","QQ32":"QQ/huaixiao.gif","QQ33":"QQ/jie.gif","QQ34":"QQ/jingkong.gif","QQ35":"QQ/jingxi.gif","QQ36":"QQ/jingya.gif","QQ37":"QQ/juhua.gif","QQ38":"QQ/keai.gif","QQ39":"QQ/kelian.gif","QQ40":"QQ/koubi.gif","QQ41":"QQ/ku.gif","QQ42":"QQ/kuaikule.gif","QQ43":"QQ/kulou.gif","QQ44":"QQ/kun.gif","QQ45":"QQ/lanqiu.gif","QQ46":"QQ/leiben.gif","QQ47":"QQ/lenghan.gif","QQ48":"QQ/liuhan.gif","QQ49":"QQ/liulei.gif","QQ50":"QQ/nanguo.gif","QQ51":"QQ/OK.gif","QQ52":"QQ/penxue.gif","QQ53":"QQ/piezui.gif","QQ54":"QQ/pijiu.gif","QQ55":"QQ/qiang.gif","QQ56":"QQ/qiaoda.gif","QQ57":"QQ/qinqin.gif","QQ58":"QQ/qiudale.gif","QQ59":"QQ/quantou.gif","QQ60":"QQ/saorao.gif","QQ61":"QQ/se.gif","QQ62":"QQ/shengli.gif","QQ63":"QQ/shouqiang.gif","QQ64":"QQ/shuai.gif","QQ65":"QQ/shui.gif","QQ66":"QQ/tiaopi.gif","QQ67":"QQ/touxiao.gif","QQ68":"QQ/tu.gif","QQ69":"QQ/tuosai.gif","QQ70":"QQ/weiqu.gif","QQ71":"QQ/weixiao.gif","QQ72":"QQ/woshou.gif","QQ73":"QQ/wozuimei.gif","QQ74":"QQ/wunai.gif","QQ75":"QQ/xia.gif","QQ76":"QQ/xiaojiujie.gif","QQ77":"QQ/xiaoku.gif","QQ78":"QQ/xiaoyanger.gif","QQ79":"QQ/xieyanxiao.gif","QQ80":"QQ/xigua.gif","QQ81":"QQ/xu.gif","QQ82":"QQ/yangtuo.gif","QQ83":"QQ/yinxian.gif","QQ84":"QQ/yiwen.gif","QQ85":"QQ/youhengheng.gif","QQ86":"QQ/youling.gif","QQ87":"QQ/yun.gif","QQ88":"QQ/zaijian.gif","QQ89":"QQ/zhayanjian.gif","QQ90":"QQ/zhemo.gif","QQ91":"QQ/zhouma.gif","QQ92":"QQ/zhuakuang.gif","QQ93":"QQ/zuohengheng.gif","Snow-Miku1":"Snow-Miku/3583066@2x.png","Snow-Miku2":"Snow-Miku/3583067@2x.png","Snow-Miku3":"Snow-Miku/3583068@2x.png","Snow-Miku4":"Snow-Miku/3583069@2x.png","Snow-Miku5":"Snow-Miku/3583070@2x.png","Snow-Miku6":"Snow-Miku/3583071@2x.png","Snow-Miku7":"Snow-Miku/3583072@2x.png","Snow-Miku8":"Snow-Miku/3583073@2x.png","Snow-Miku9":"Snow-Miku/3583074@2x.png","Snow-Miku10":"Snow-Miku/3583075@2x.png","Snow-Miku11":"Snow-Miku/3583076@2x.png","Snow-Miku12":"Snow-Miku/3583077@2x.png","Snow-Miku13":"Snow-Miku/3583078@2x.png","Snow-Miku14":"Snow-Miku/3583079@2x.png","Snow-Miku15":"Snow-Miku/3583080@2x.png","Snow-Miku16":"Snow-Miku/3583081@2x.png","Snow-Miku17":"Snow-Miku/3583082@2x.png","Snow-Miku18":"Snow-Miku/3583083@2x.png","Snow-Miku19":"Snow-Miku/3583084@2x.png","Snow-Miku20":"Snow-Miku/3583085@2x.png","Snow-Miku21":"Snow-Miku/3583086@2x.png","Snow-Miku22":"Snow-Miku/3583087@2x.png","Snow-Miku23":"Snow-Miku/3583088@2x.png","Snow-Miku24":"Snow-Miku/3583089@2x.png","Snow-Miku25":"Snow-Miku/3583090@2x.png","Snow-Miku26":"Snow-Miku/3583091@2x.png","Snow-Miku27":"Snow-Miku/3583092@2x.png","Snow-Miku28":"Snow-Miku/3583093@2x.png","Snow-Miku29":"Snow-Miku/3583094@2x.png","Snow-Miku30":"Snow-Miku/3583095@2x.png","Snow-Miku31":"Snow-Miku/3583096@2x.png","Snow-Miku32":"Snow-Miku/3583097@2x.png","Snow-Miku33":"Snow-Miku/3583098@2x.png","Snow-Miku34":"Snow-Miku/3583099@2x.png","Snow-Miku35":"Snow-Miku/3583100@2x.png","Snow-Miku36":"Snow-Miku/3583101@2x.png","Snow-Miku37":"Snow-Miku/3583102@2x.png","Snow-Miku38":"Snow-Miku/3583103@2x.png","Snow-Miku39":"Snow-Miku/3583104@2x.png","Snow-Miku40":"Snow-Miku/3583105@2x.png","Tsuri-me-ju_mimi1":"Tsuri-me-ju_mimi/10753776_key@2x.png","Tsuri-me-ju_mimi2":"Tsuri-me-ju_mimi/10753777_key@2x.png","Tsuri-me-ju_mimi3":"Tsuri-me-ju_mimi/10753778_key@2x.png","Tsuri-me-ju_mimi4":"Tsuri-me-ju_mimi/10753779_key@2x.png","Tsuri-me-ju_mimi5":"Tsuri-me-ju_mimi/10753780_key@2x.png","Tsuri-me-ju_mimi6":"Tsuri-me-ju_mimi/10753781_key@2x.png","Tsuri-me-ju_mimi7":"Tsuri-me-ju_mimi/10753782_key@2x.png","Tsuri-me-ju_mimi8":"Tsuri-me-ju_mimi/10753783_key@2x.png","Tsuri-me-ju_mimi9":"Tsuri-me-ju_mimi/10753784_key@2x.png","Tsuri-me-ju_mimi10":"Tsuri-me-ju_mimi/10753785_key@2x.png","Tsuri-me-ju_mimi11":"Tsuri-me-ju_mimi/10753786_key@2x.png","Tsuri-me-ju_mimi12":"Tsuri-me-ju_mimi/10753787_key@2x.png","Tsuri-me-ju_mimi13":"Tsuri-me-ju_mimi/10753788_key@2x.png","Tsuri-me-ju_mimi14":"Tsuri-me-ju_mimi/10753789_key@2x.png","Tsuri-me-ju_mimi15":"Tsuri-me-ju_mimi/10753790_key@2x.png","Tsuri-me-ju_mimi16":"Tsuri-me-ju_mimi/10753791_key@2x.png","Tsuri-me-ju_mimi17":"Tsuri-me-ju_mimi/10753792_key@2x.png","Tsuri-me-ju_mimi18":"Tsuri-me-ju_mimi/10753793_key@2x.png","Tsuri-me-ju_mimi19":"Tsuri-me-ju_mimi/10753794_key@2x.png","Tsuri-me-ju_mimi20":"Tsuri-me-ju_mimi/10753795_key@2x.png","Tsuri-me-ju_mimi21":"Tsuri-me-ju_mimi/10753796_key@2x.png","Tsuri-me-ju_mimi22":"Tsuri-me-ju_mimi/10753797_key@2x.png","Tsuri-me-ju_mimi23":"Tsuri-me-ju_mimi/10753798_key@2x.png","Tsuri-me-ju_mimi24":"Tsuri-me-ju_mimi/10753799_key@2x.png","Tsuri-me-ju_mimi25":"Tsuri-me-ju_mimi/10753800_key@2x.png","Tsuri-me-ju_mimi26":"Tsuri-me-ju_mimi/10753801_key@2x.png","Tsuri-me-ju_mimi27":"Tsuri-me-ju_mimi/10753802_key@2x.png","Tsuri-me-ju_mimi28":"Tsuri-me-ju_mimi/10753803_key@2x.png","Tsuri-me-ju_mimi29":"Tsuri-me-ju_mimi/10753804_key@2x.png","Tsuri-me-ju_mimi30":"Tsuri-me-ju_mimi/10753805_key@2x.png","Tsuri-me-ju_mimi31":"Tsuri-me-ju_mimi/10753806_key@2x.png","Tsuri-me-ju_mimi32":"Tsuri-me-ju_mimi/10753807_key@2x.png","Tsuri-me-ju_mimi33":"Tsuri-me-ju_mimi/10753808_key@2x.png","Tsuri-me-ju_mimi34":"Tsuri-me-ju_mimi/10753809_key@2x.png","Tsuri-me-ju_mimi35":"Tsuri-me-ju_mimi/10753810_key@2x.png","Tsuri-me-ju_mimi36":"Tsuri-me-ju_mimi/10753811_key@2x.png","Tsuri-me-ju_mimi37":"Tsuri-me-ju_mimi/10753812_key@2x.png","Tsuri-me-ju_mimi38":"Tsuri-me-ju_mimi/10753813_key@2x.png","Tsuri-me-ju_mimi39":"Tsuri-me-ju_mimi/10753814_key@2x.png","Tsuri-me-ju_mimi40":"Tsuri-me-ju_mimi/10753815_key@2x.png"},
      enableQQ: true,
      path: window.location.pathname,
    });

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/gh/HCLonely/Valine@latest/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src='https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js'></script><script src="https://cdn.jsdelivr.net/npm/butterfly-friend@1.0.4/dist/friend.min.js"></script><script src="/js/checkbox.js"></script><script src="/js/botui.js"></script><script src="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@master/xkTool/文件夹名/xkTool.js"></script><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/Sum/title.js"></script>#樱花<script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="true" data-text="KO NO DIO哒！,奥利给,赛Q来打,喵帕斯~,暗中观察,阿巴阿巴,达咩哟~" data-fontsize="15px" data-random="true" async="async"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config_change',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/shuoshuo/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  if (typeof gtag === 'function') {
    gtag('config', '', {'page_path': window.location.pathname});
  }

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})


document.addEventListener('pjax:send', function () {
  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>